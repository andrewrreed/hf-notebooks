{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Synthetic Entities with `Outlines`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan: Given a domain/industry, need to generate synthetic entities that are comprised of:\n",
    "\n",
    "1. First, given a domain/industry name and a description of that domain, generate a list of N possible job titles (along with job description)\n",
    "\n",
    "IndustryJobs - Industry Name - Industry Description - Job Titles\n",
    "\n",
    "2. Then for each job title/description generate, generate a job entity:\n",
    "\n",
    "Job Entity - Job Title (str) - Job Description (str) - Associated Job Postings/Position (List[str]) - Job Skills (List[str])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "import outlines\n",
    "import huggingface_hub\n",
    "from pydantic import BaseModel, conlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# huggingface_hub.interpreter_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Job(BaseModel):\n",
    "#     title: str\n",
    "#     description: str\n",
    "#     skills: conlist(str, min_length=3, max_length=3)  # type: ignore\n",
    "#     relevant_postings: conlist(str, min_length=3, max_length=3)  # type: ignore\n",
    "\n",
    "\n",
    "# class IndustryJobs(BaseModel):\n",
    "#     industry_name: str\n",
    "#     industry_description: str\n",
    "#     industry_jobs: conlist(Job, min_length=3, max_length=3)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Job(BaseModel):\n",
    "    title: str\n",
    "    description: str\n",
    "    skills: List[str]\n",
    "    relevant_postings: List[str]\n",
    "\n",
    "\n",
    "class IndustryJobs(BaseModel):\n",
    "    industry_name: str\n",
    "    industry_description: str\n",
    "    industry_jobs: List[Job]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@outlines.prompt\n",
    "def industry_jobs_prompt(name: str, description: str) -> IndustryJobs:\n",
    "    \"\"\"\n",
    "    You are a expert human resources professional with broad and deep knowledge of talent profiles across every industry.\n",
    "    Your job is to generate a list of 3 diverse and popular Job Profiles that cover a range of functions, from foundational\n",
    "    roles to innovative and emerging positions based on a provided industry name and description.\n",
    "\n",
    "    For each Job Profile, you need to provide the following details:\n",
    "    - Job Title: The title of the job\n",
    "    - Job Description: A brief description of the job role and responsibilities\n",
    "    - Skills: A list of 3 skills required for the job\n",
    "    - Relevant Job Postings: A list of 3 relevant job postings as they might appear on popular job portals\n",
    "\n",
    "    Here is the new industry you need to generate jobs for:\n",
    "    Industry Name: {{ name }}\n",
    "    Industry Description: {{ description }}\n",
    "    Jobs Profiles:\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "879fb0f5a49c42399f4580b6abffe04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from outlines import models\n",
    "\n",
    "model_id = \"google/gemma-7b-it\"\n",
    "\n",
    "model = models.transformers(\n",
    "    model_id, model_kwargs={\"device_map\": \"auto\", \"torch_dtype\": torch.bfloat16}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = industry_jobs_prompt(\n",
    "    name=\"Hospitality\",\n",
    "    description=\"The hospitality industry is a broad category of fields within the service industry that includes lodging, event planning, theme parks, transportation, cruise line, and additional fields within the tourism industry.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a expert human resources professional with broad and deep knowledge of talent profiles across every industry.\n",
      "Your job is to generate a list of 3 diverse and popular Job Profiles that cover a range of functions, from foundational\n",
      "roles to innovative and emerging positions based on a provided industry name and description.\n",
      "\n",
      "For each Job Profile, you need to provide the following details:\n",
      "- Job Title: The title of the job\n",
      "- Job Description: A brief description of the job role and responsibilities\n",
      "- Skills: A list of 3 skills required for the job\n",
      "- Relevant Job Postings: A list of 3 relevant job postings as they might appear on popular job portals\n",
      "\n",
      "Here is the new industry you need to generate jobs for:\n",
      "Industry Name: Hospitality\n",
      "Industry Description: The hospitality industry is a broad category of fields within the service industry that includes lodging, event planning, theme parks, transportation, cruise line, and additional fields within the tourism industry.\n",
      "Jobs Profiles:\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_generator = outlines.generate.json(model, IndustryJobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (8192) must match the size of tensor b (8193) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[0;32m~/hf-notebooks/synthetic-entity-generation/.venv/lib/python3.9/site-packages/outlines/generate/api.py:200\u001b[0m, in \u001b[0;36mSequenceGenerator.__call__\u001b[0;34m(self, prompts, max_tokens, stop_at, rng)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         last_state \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(states)\n\u001b[1;32m    201\u001b[0m         \u001b[39mif\u001b[39;00m max_tokens \u001b[39mor\u001b[39;00m stop_sequences:\n\u001b[1;32m    202\u001b[0m             token_ids \u001b[39m=\u001b[39m last_state\u001b[39m.\u001b[39mtoken_ids\n",
      "File \u001b[0;32m~/hf-notebooks/synthetic-entity-generation/.venv/lib/python3.9/site-packages/outlines/generate/generator.py:71\u001b[0m, in \u001b[0;36msequence_generator\u001b[0;34m(model, sampler, fsms, token_ids, sequence_weights, attention_masks, fsm_states, rng)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m         logits, kv_cache \u001b[39m=\u001b[39m model(token_ids, attention_masks, kv_cache)\n\u001b[1;32m     72\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:  \u001b[39m# Exceeding the context length\u001b[39;00m\n\u001b[1;32m     73\u001b[0m         \u001b[39mraise\u001b[39;00m ContextLengthExceededError(\n\u001b[1;32m     74\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe input length exceeds the context length of the model.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m         )\n",
      "File \u001b[0;32m~/hf-notebooks/synthetic-entity-generation/.venv/lib/python3.9/site-packages/outlines/models/transformers.py:116\u001b[0m, in \u001b[0;36mTransformer.__call__\u001b[0;34m(self, input_ids, attention_mask, past_key_values)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m    111\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    112\u001b[0m     input_ids: torch\u001b[39m.\u001b[39mLongTensor,\n\u001b[1;32m    113\u001b[0m     attention_mask: torch\u001b[39m.\u001b[39mLongTensor,\n\u001b[1;32m    114\u001b[0m     past_key_values: Optional[Tuple] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    115\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mFloatTensor:\n\u001b[0;32m--> 116\u001b[0m     logits, kv_cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(input_ids, attention_mask, past_key_values)\n\u001b[1;32m    117\u001b[0m     next_token_logits \u001b[39m=\u001b[39m logits[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n\u001b[1;32m    119\u001b[0m     \u001b[39mreturn\u001b[39;00m next_token_logits, kv_cache\n",
      "File \u001b[0;32m~/hf-notebooks/synthetic-entity-generation/.venv/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/hf-notebooks/synthetic-entity-generation/.venv/lib/python3.9/site-packages/outlines/models/transformers.py:99\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, input_ids, attention_mask, past_key_values)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mif\u001b[39;00m past_key_values:\n\u001b[1;32m     97\u001b[0m     input_ids \u001b[39m=\u001b[39m input_ids[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 99\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m    100\u001b[0m     input_ids,\n\u001b[1;32m    101\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    102\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    103\u001b[0m     output_attentions\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    104\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    105\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    106\u001b[0m )\n\u001b[1;32m    108\u001b[0m \u001b[39mreturn\u001b[39;00m output\u001b[39m.\u001b[39mlogits, output\u001b[39m.\u001b[39mpast_key_values\n",
      "File \u001b[0;32m~/hf-notebooks/synthetic-entity-generation/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/hf-notebooks/synthetic-entity-generation/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/hf-notebooks/synthetic-entity-generation/.venv/lib/python3.9/site-packages/transformers/models/gemma/modeling_gemma.py:1067\u001b[0m, in \u001b[0;36mGemmaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1064\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m   1066\u001b[0m \u001b[39m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1067\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m   1068\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m   1069\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1070\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1071\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1072\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1073\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1074\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1075\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1076\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1077\u001b[0m     cache_position\u001b[39m=\u001b[39;49mcache_position,\n\u001b[1;32m   1078\u001b[0m )\n\u001b[1;32m   1080\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1081\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m~/hf-notebooks/synthetic-entity-generation/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/hf-notebooks/synthetic-entity-generation/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/hf-notebooks/synthetic-entity-generation/.venv/lib/python3.9/site-packages/transformers/models/gemma/modeling_gemma.py:876\u001b[0m, in \u001b[0;36mGemmaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[39mif\u001b[39;00m position_ids \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    874\u001b[0m     position_ids \u001b[39m=\u001b[39m cache_position\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m--> 876\u001b[0m causal_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_causal_mask(attention_mask, inputs_embeds)\n\u001b[1;32m    878\u001b[0m \u001b[39m# embed positions\u001b[39;00m\n\u001b[1;32m    879\u001b[0m hidden_states \u001b[39m=\u001b[39m inputs_embeds\n",
      "File \u001b[0;32m~/hf-notebooks/synthetic-entity-generation/.venv/lib/python3.9/site-packages/transformers/models/gemma/modeling_gemma.py:972\u001b[0m, in \u001b[0;36mGemmaModel._update_causal_mask\u001b[0;34m(self, attention_mask, input_tensor)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[39mif\u001b[39;00m attention_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m attention_mask\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    971\u001b[0m     mask_length \u001b[39m=\u001b[39m attention_mask\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m--> 972\u001b[0m     padding_mask \u001b[39m=\u001b[39m causal_mask[\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m, :mask_length]\u001b[39m.\u001b[39;49meq(\u001b[39m0.0\u001b[39;49m) \u001b[39m*\u001b[39;49m attention_mask[:, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, :]\u001b[39m.\u001b[39;49meq(\u001b[39m0.0\u001b[39;49m)\n\u001b[1;32m    973\u001b[0m     causal_mask[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, :mask_length] \u001b[39m=\u001b[39m causal_mask[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, :mask_length]\u001b[39m.\u001b[39mmasked_fill(\n\u001b[1;32m    974\u001b[0m         padding_mask, torch\u001b[39m.\u001b[39mfinfo(dtype)\u001b[39m.\u001b[39mmin\n\u001b[1;32m    975\u001b[0m     )\n\u001b[1;32m    977\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39m_attn_implementation \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msdpa\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (8192) must match the size of tensor b (8193) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "out = jobs_generator(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'industry_name': 'Hospitality',\n",
       " 'industry_description': 'The hospitality industry is a broad category of fields within the service industry that includes lodging, event planning, theme parks, transportation, cruise line, and additional fields within the tourism industry.',\n",
       " 'industry_jobs': [{'title': 'Front Desk Agent',\n",
       "   'description': 'Provides a warm and professional welcome to guests, assists with check-in/out procedures, and handles various customer service inquiries.',\n",
       "   'skills': ['Excellent communication and interpersonal skills',\n",
       "    'Strong customer service orientation',\n",
       "    'Proficient in a variety of software systems'],\n",
       "   'relevant_postings': ['Front Desk Agent - The Peninsula, New York, NY',\n",
       "    'Front Desk Agent - The Ritz-Carlton, Chicago, IL',\n",
       "    'Front Desk Agent - The Four Seasons Hotel, Los Angeles, CA']},\n",
       "  {'title': 'Chef',\n",
       "   'description': 'Plans, prepares, and cooks a variety of culinary creations for guests, maintains kitchen cleanliness and safety standards.',\n",
       "   'skills': ['Exceptional culinary skills',\n",
       "    'Highly organized and efficient',\n",
       "    'Strong leadership and teamwork abilities'],\n",
       "   'relevant_postings': ['Chef - The Blue Moon, Seattle, WA',\n",
       "    'Chef - The Michelin-starred Restaurant, New York, NY',\n",
       "    'Chef - The Nobu, Miami Beach, FL']},\n",
       "  {'title': 'Event Manager',\n",
       "   'description': 'Plans, organizes, and executes events for various clients, manages budgets and vendor relationships.',\n",
       "   'skills': ['Excellent organizational and planning skills',\n",
       "    'Strong communication and interpersonal skills',\n",
       "    'Proficient in event management software'],\n",
       "   'relevant_postings': ['Event Manager - The Grand Hotel, New York, NY',\n",
       "    'Event Manager - The Waldorf Astoria, Chicago, IL',\n",
       "    'Event Manager - The Bellagio, Las Vegas, NV']}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (8192) must match the size of tensor b (8193) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[0;32m~/hf-notebooks/synthetic-entity-generation/.venv/lib/python3.9/site-packages/outlines/generate/api.py:200\u001b[0m, in \u001b[0;36mSequenceGenerator.__call__\u001b[0;34m(self, prompts, max_tokens, stop_at, rng)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         last_state \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(states)\n\u001b[1;32m    201\u001b[0m         \u001b[39mif\u001b[39;00m max_tokens \u001b[39mor\u001b[39;00m stop_sequences:\n\u001b[1;32m    202\u001b[0m             token_ids \u001b[39m=\u001b[39m last_state\u001b[39m.\u001b[39mtoken_ids\n",
      "File \u001b[0;32m~/hf-notebooks/synthetic-entity-generation/.venv/lib/python3.9/site-packages/outlines/generate/generator.py:71\u001b[0m, in \u001b[0;36msequence_generator\u001b[0;34m(model, sampler, fsms, token_ids, sequence_weights, attention_masks, fsm_states, rng)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m         logits, kv_cache \u001b[39m=\u001b[39m model(token_ids, attention_masks, kv_cache)\n\u001b[1;32m     72\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:  \u001b[39m# Exceeding the context length\u001b[39;00m\n\u001b[1;32m     73\u001b[0m         \u001b[39mraise\u001b[39;00m ContextLengthExceededError(\n\u001b[1;32m     74\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe input length exceeds the context length of the model.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m         )\n",
      "File \u001b[0;32m~/hf-notebooks/synthetic-entity-generation/.venv/lib/python3.9/site-packages/outlines/models/transformers.py:116\u001b[0m, in \u001b[0;36mTransformer.__call__\u001b[0;34m(self, input_ids, attention_mask, past_key_values)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m    111\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    112\u001b[0m     input_ids: torch\u001b[39m.\u001b[39mLongTensor,\n\u001b[1;32m    113\u001b[0m     attention_mask: torch\u001b[39m.\u001b[39mLongTensor,\n\u001b[1;32m    114\u001b[0m     past_key_values: Optional[Tuple] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    115\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mFloatTensor:\n\u001b[0;32m--> 116\u001b[0m     logits, kv_cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(input_ids, attention_mask, past_key_values)\n\u001b[1;32m    117\u001b[0m     next_token_logits \u001b[39m=\u001b[39m logits[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n\u001b[1;32m    119\u001b[0m     \u001b[39mreturn\u001b[39;00m next_token_logits, kv_cache\n",
      "File \u001b[0;32m~/hf-notebooks/synthetic-entity-generation/.venv/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/hf-notebooks/synthetic-entity-generation/.venv/lib/python3.9/site-packages/outlines/models/transformers.py:99\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, input_ids, attention_mask, past_key_values)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mif\u001b[39;00m past_key_values:\n\u001b[1;32m     97\u001b[0m     input_ids \u001b[39m=\u001b[39m input_ids[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 99\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m    100\u001b[0m     input_ids,\n\u001b[1;32m    101\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    102\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    103\u001b[0m     output_attentions\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    104\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    105\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    106\u001b[0m )\n\u001b[1;32m    108\u001b[0m \u001b[39mreturn\u001b[39;00m output\u001b[39m.\u001b[39mlogits, output\u001b[39m.\u001b[39mpast_key_values\n",
      "File \u001b[0;32m~/hf-notebooks/synthetic-entity-generation/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/hf-notebooks/synthetic-entity-generation/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/hf-notebooks/synthetic-entity-generation/.venv/lib/python3.9/site-packages/transformers/models/gemma/modeling_gemma.py:1067\u001b[0m, in \u001b[0;36mGemmaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1064\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m   1066\u001b[0m \u001b[39m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1067\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m   1068\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m   1069\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1070\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1071\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1072\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1073\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1074\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1075\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1076\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1077\u001b[0m     cache_position\u001b[39m=\u001b[39;49mcache_position,\n\u001b[1;32m   1078\u001b[0m )\n\u001b[1;32m   1080\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1081\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m~/hf-notebooks/synthetic-entity-generation/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/hf-notebooks/synthetic-entity-generation/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/hf-notebooks/synthetic-entity-generation/.venv/lib/python3.9/site-packages/transformers/models/gemma/modeling_gemma.py:876\u001b[0m, in \u001b[0;36mGemmaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[39mif\u001b[39;00m position_ids \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    874\u001b[0m     position_ids \u001b[39m=\u001b[39m cache_position\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m--> 876\u001b[0m causal_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_causal_mask(attention_mask, inputs_embeds)\n\u001b[1;32m    878\u001b[0m \u001b[39m# embed positions\u001b[39;00m\n\u001b[1;32m    879\u001b[0m hidden_states \u001b[39m=\u001b[39m inputs_embeds\n",
      "File \u001b[0;32m~/hf-notebooks/synthetic-entity-generation/.venv/lib/python3.9/site-packages/transformers/models/gemma/modeling_gemma.py:972\u001b[0m, in \u001b[0;36mGemmaModel._update_causal_mask\u001b[0;34m(self, attention_mask, input_tensor)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[39mif\u001b[39;00m attention_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m attention_mask\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    971\u001b[0m     mask_length \u001b[39m=\u001b[39m attention_mask\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m--> 972\u001b[0m     padding_mask \u001b[39m=\u001b[39m causal_mask[\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m, :mask_length]\u001b[39m.\u001b[39;49meq(\u001b[39m0.0\u001b[39;49m) \u001b[39m*\u001b[39;49m attention_mask[:, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, :]\u001b[39m.\u001b[39;49meq(\u001b[39m0.0\u001b[39;49m)\n\u001b[1;32m    973\u001b[0m     causal_mask[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, :mask_length] \u001b[39m=\u001b[39m causal_mask[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, :mask_length]\u001b[39m.\u001b[39mmasked_fill(\n\u001b[1;32m    974\u001b[0m         padding_mask, torch\u001b[39m.\u001b[39mfinfo(dtype)\u001b[39m.\u001b[39mmin\n\u001b[1;32m    975\u001b[0m     )\n\u001b[1;32m    977\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39m_attn_implementation \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msdpa\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (8192) must match the size of tensor b (8193) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "out = outlines.generate.json(model, IndustryJobs)(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IndustryJobs(industry_name='Hospitality', industry_description='The hospitality industry is a broad category of fields within the service industry that includes lodging, event planning, theme parks, transportation, cruise line, and additional fields within the tourism industry.', industry_jobs=[Job(title='Front Desk Agent', description='The Front Desk Agent is responsible for providing a welcoming and efficient environment for guests by completing various tasks such as registration, room assignments, and resolving complaints.', skills=['Excellent communication and interpersonal skills', 'Strong customer service orientation', 'Proficient in various software systems', 'Ability to work independently and collaboratively', 'Attention to detail'], relevant_postings=['Hotel Front Desk Agent Jobs', 'Front Desk Agent Jobs in New York', 'Front Desk Agent Job Posting']), Job(title='Hotel Room Attendant', description='The Hotel Room Attendant is responsible for maintaining cleanliness and providing a comfortable guest environment in rooms.', skills=['Cleanliness and tidiness', 'Attention to detail', 'Good housekeeping practices', 'Customer service orientation', 'Strong work ethic'], relevant_postings=['Hotel Room Attendant Jobs', 'Room Attendant Jobs in Los Angeles', 'Room Attendant Job Posting']), Job(title='Event Manager', description='The Event Manager is responsible for planning, organizing, and executing events of all sizes.', skills=['Excellent communication and interpersonal skills', 'Strong organizational skills', 'Creativity', 'Project management', 'Event execution'], relevant_postings=['Event Manager Jobs', 'Event Manager Jobs in Chicago', 'Event Manager Job Posting'])])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'industry_name': 'Hospitality',\n",
       " 'industry_description': 'The hospitality industry is a broad category of fields within the service industry that includes lodging, event planning, theme parks, transportation, cruise line, and additional fields within the tourism industry.',\n",
       " 'industry_jobs': [{'title': 'Front Desk Agent',\n",
       "   'description': 'The Front Desk Agent is responsible for providing a welcoming and efficient environment for guests by completing various tasks such as registration, room assignments, and resolving complaints.',\n",
       "   'skills': ['Excellent communication and interpersonal skills',\n",
       "    'Strong customer service orientation',\n",
       "    'Proficient in various software systems',\n",
       "    'Ability to work independently and collaboratively',\n",
       "    'Attention to detail'],\n",
       "   'relevant_postings': ['Hotel Front Desk Agent Jobs',\n",
       "    'Front Desk Agent Jobs in New York',\n",
       "    'Front Desk Agent Job Posting']},\n",
       "  {'title': 'Hotel Room Attendant',\n",
       "   'description': 'The Hotel Room Attendant is responsible for maintaining cleanliness and providing a comfortable guest environment in rooms.',\n",
       "   'skills': ['Cleanliness and tidiness',\n",
       "    'Attention to detail',\n",
       "    'Good housekeeping practices',\n",
       "    'Customer service orientation',\n",
       "    'Strong work ethic'],\n",
       "   'relevant_postings': ['Hotel Room Attendant Jobs',\n",
       "    'Room Attendant Jobs in Los Angeles',\n",
       "    'Room Attendant Job Posting']},\n",
       "  {'title': 'Event Manager',\n",
       "   'description': 'The Event Manager is responsible for planning, organizing, and executing events of all sizes.',\n",
       "   'skills': ['Excellent communication and interpersonal skills',\n",
       "    'Strong organizational skills',\n",
       "    'Creativity',\n",
       "    'Project management',\n",
       "    'Event execution'],\n",
       "   'relevant_postings': ['Event Manager Jobs',\n",
       "    'Event Manager Jobs in Chicago',\n",
       "    'Event Manager Job Posting']}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IndustryJobs(industry_name='Software Development', industry_description='Software development is the process of conceiving, specifying, designing, programming, documenting, testing, and bug fixing involved in creating and maintaining applications, frameworks, or other software components.', industry_jobs=[Job(job_title='Software Engineer', job_description='Software engineers design, code, test, and maintain software applications. They are responsible for all aspects of the software development process, from initial planning to implementation.'), Job(job_title='Full-Stack Developer', job_description='Full-stack developers are responsible for building and maintaining software applications across all platforms. They have strong proficiency in web development technologies like HTML, CSS, and JavaScript, as well as in back-end languages like Python or Java.'), Job(job_title='Junior Software Engineer', job_description='Junior software engineers assist senior engineers in designing, coding, and testing software applications. They are typically responsible for smaller tasks and are often paired with a senior engineer for guidance.')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Software Development'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.industry_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Software development is the process of conceiving, specifying, designing, programming, documenting, testing, and bug fixing involved in creating and maintaining applications, frameworks, or other software components.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.industry_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Software Engineer\n",
      "Software engineers design, code, test, and maintain software applications. They are responsible for all aspects of the software development process, from initial planning to implementation.\n",
      "\n",
      "Full-Stack Developer\n",
      "Full-stack developers are responsible for building and maintaining software applications across all platforms. They have strong proficiency in web development technologies like HTML, CSS, and JavaScript, as well as in back-end languages like Python or Java.\n",
      "\n",
      "Junior Software Engineer\n",
      "Junior software engineers assist senior engineers in designing, coding, and testing software applications. They are typically responsible for smaller tasks and are often paired with a senior engineer for guidance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for job in out.industry_jobs:\n",
    "    print(job.job_title)\n",
    "    print(job.job_description)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/hf-notebooks/synthetic-entity-generation/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:49<00:00, 12.30s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, pipeline\n",
    "import torch\n",
    "\n",
    "model = \"google/gemma-7b-it\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who are you? Please, answer in pirate-speak.\"},\n",
    "]\n",
    "prompt = pipeline.tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "outputs = pipeline(\n",
    "    prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<bos><start_of_turn>user\\nWho are you? Please, answer in pirate-speak.<end_of_turn>\\n<start_of_turn>model\\nAvast, me heartie, I am a swabblin' digital pirate, ready to pillage the high seas of the digital realm.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0][\"generated_text\"][]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing demo example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from pydantic import BaseModel, conlist, constr, StringConstraints\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "import outlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from outlines import models\n",
    "\n",
    "model_id = \"google/gemma-7b-it\"\n",
    "\n",
    "model = models.transformers(\n",
    "    model_id, model_kwargs={\"device_map\": \"auto\", \"torch_dtype\": torch.bfloat16}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionChoice(str, Enum):\n",
    "    A = \"The key to my heart is\"\n",
    "    B = \"The first item on my bucket list is\"\n",
    "    C = \"Perks of dating me\"\n",
    "    D = \"Message me if you also love\"\n",
    "    E = \"People would describe me as\"\n",
    "    F = \"I can beat you in a game of\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class QuestionAnswer:\n",
    "    question: QuestionChoice\n",
    "    answer: str\n",
    "\n",
    "\n",
    "class DatingProfile(BaseModel):\n",
    "    bio: Annotated[str, StringConstraints(min_length=10, max_length=300)]\n",
    "    job: Annotated[str, StringConstraints(max_length=50)]\n",
    "    interests: conlist(str, min_length=1, max_length=5)  # type: ignore\n",
    "    qna1: QuestionAnswer\n",
    "    qna2: QuestionAnswer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Example:\n",
    "    description: str\n",
    "    profile: DatingProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@outlines.prompt\n",
    "def dating_profile_prompt(description: str, examples: list[Example]):\n",
    "    \"\"\"\n",
    "    You are a world-renowned matchmaker who understands the modern dating\n",
    "    market. Your job is to generate dating app profiles for male clients\n",
    "    interested in women based on a provided description. The profiles should be\n",
    "    authentic, show off their strengths, and maximize their likelihood of\n",
    "    getting matches on dating apps.  Here are some examples of past clients that\n",
    "    you have successfully created profiles for:\n",
    "\n",
    "    {% for example in examples %}\n",
    "    Description:\n",
    "    {{ example.description }}\n",
    "    Profile:\n",
    "    {{ example.profile }}\n",
    "    {% endfor %}\n",
    "\n",
    "    Here is the new client who you need to create a profile for:\n",
    "    Description: {{ description }}\n",
    "    Profile:\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples: list[Example] = [\n",
    "    Example(\n",
    "        description=\"I'm an author and former professional soccer player living in Seattle who publishes popular fiction books. A typical day for me starts by hanging out with my cat, drinking a coffee, and reading as much as I can in a few hours. Then, I'll prepare a quick smoothie before starting to write for a few hours, take a break with soccer or running a few miles, and finally meet friends for dinner at a new, hip restaurant in the evening. Sometimes we go axe-throwing afterwards, or play poker, or watch a comedy show, or visit a dive bar. On my vacations, I travel extensively to countries South America, Europe, and Asia, with the goal of visiting them all!\",\n",
    "        profile=DatingProfile(\n",
    "            bio=\"Adventurer, dreamer, author, and soccer enthusiast. Life’s too short to waste time so I make the most of each day by exploring new places and playing with my friends on the pitch. What’s your favorite way to get out and have fun?\",\n",
    "            job=\"Famous Soccer Player -> Famous Author\",\n",
    "            interests=[\"Soccer\", \"Travel\", \"Friends\", \"Books\", \"Fluffy Animals\"],\n",
    "            qna1=QuestionAnswer(\n",
    "                question=QuestionChoice.B, answer=\"swim in all seven oceans!\"\n",
    "            ),\n",
    "            qna2=QuestionAnswer(\n",
    "                question=QuestionChoice.E,\n",
    "                answer=\"fun-loving, adventurous, and a little bit crazy\",\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    Example(\n",
    "        description=\"I run my company and build houses for a living. I'm a big fan of the outdoors and love to go hiking, camping, and fishing. I don't like video games, but do like to watch movies. My love language is home-cooked food, and I'm looking for someone who isn't afraid to get their hands dirty.\",\n",
    "        profile=DatingProfile(\n",
    "            bio=\"If you're looking for a Montana man who loves to get outdoors and hunt, and who's in-tune with his masculinity then I'm your guy!\",\n",
    "            job=\"House Construction Manager / Entrepreneur\",\n",
    "            interests=[\"Hunting\", \"Hiking\", \"The outdoors\", \"Home-cooked food\"],\n",
    "            qna1=QuestionAnswer(question=QuestionChoice.A, answer=\"food made at home\"),\n",
    "            qna2=QuestionAnswer(\n",
    "                question=QuestionChoice.C,\n",
    "                answer=\"having a man in your life who can fix anything\",\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    Example(\n",
    "        description=\"I run my own Youtube channel with 10M subscribers. I love working with kids, and my audience skews pretty young too. In my free time, I play Fortnite and Roblox. I'm looking for someone who is also a gamer and likes to have fun. I'm learning Japanese in my free time as well as how to cook.\",\n",
    "        profile=DatingProfile(\n",
    "            bio=\"Easy on the eyes (find me on Youtube!) and great with kids. What more do you need?\",\n",
    "            job=\"Youtuber 10M+ subscribers\",\n",
    "            interests=[\"Kids\", \"Gaming\", \"Japanese\"],\n",
    "            qna1=QuestionAnswer(question=QuestionChoice.D, answer=\"anime and gaming!\"),\n",
    "            qna2=QuestionAnswer(question=QuestionChoice.F, answer=\"Fortnite, gg ez\"),\n",
    "        ),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_description = \"\"\"I'm a laid-back lawyer who spends a lot of his free-time\n",
    "gaming. I work in a corporate office, but ended up here after the start-up  I\n",
    "cofounded got acquired, so still play ping pong with my cool coworkers every\n",
    "day.  I have a bar at home where I make cocktails, which is great for\n",
    "entertaining  friends. I secretly like to wear suits and get a new one tailored\n",
    "every few  months. I also like weddings because I get to wear those suits, and\n",
    "it's  a good excuse for a date. I watch the latest series because I'm paying,\n",
    "with my hard-earned money, for every streaming service.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f917c73d130>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/hf-notebooks/synthetic-entity-generation/.venv/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "prompt = dating_profile_prompt(new_description, samples)\n",
    "profile = outlines.generate.json(model, DatingProfile)\n",
    "out = profile(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
