{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train SpanMarker to Improve Single Entity NER Model\n",
    "\n",
    "Goals:\n",
    "1. Build custom dataset specifically for \"Person\" entity\n",
    "2. Train SpanMarker NER model (maybe hyperparameter optimization)\n",
    "3. Evaluate performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install span_marker[wandb] names-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Explore and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'fine_ner_tags'],\n",
       "        num_rows: 131767\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'fine_ner_tags'],\n",
       "        num_rows: 18824\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'fine_ner_tags'],\n",
       "        num_rows: 37648\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_id = \"DFKI-SLT/few-nerd\"\n",
    "dataset = load_dataset(dataset_id, \"supervised\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0', 'tokens': ['Paul', 'International', 'airport', '.'], 'ner_tags': [0, 0, 0, 0], 'fine_ner_tags': [0, 0, 0, 0]}\n",
      "\n",
      "{'id': '1', 'tokens': ['It', 'starred', 'Hicks', \"'s\", 'wife', ',', 'Ellaline', 'Terriss', 'and', 'Edmund', 'Payne', '.'], 'ner_tags': [0, 0, 7, 0, 0, 0, 7, 7, 0, 7, 7, 0], 'fine_ner_tags': [0, 0, 51, 0, 0, 0, 50, 50, 0, 50, 50, 0]}\n",
      "\n",
      "{'id': '2', 'tokens': ['``', 'Time', '``', 'magazine', 'said', 'the', 'film', 'was', '``', 'a', 'multimillion', 'dollar', 'improvisation', 'that', 'does', 'everything', 'but', 'what', 'the', 'title', 'promises', \"''\", 'and', 'suggested', 'that', '``', 'writer', 'George', 'Axelrod', '(', '``', 'The', 'Seven', 'Year', 'Itch', '``', ')', 'and', 'director', 'Richard', 'Quine', 'should', 'have', 'taken', 'a', 'hint', 'from', 'Holden', '[', \"'s\", 'character', 'Richard', 'Benson', ']', ',', 'who', 'writes', 'his', 'movie', ',', 'takes', 'a', 'long', 'sober', 'look', 'at', 'what', 'he', 'has', 'wrought', ',', 'and', 'burns', 'it', '.', \"''\"], 'ner_tags': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'fine_ner_tags': [0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 51, 51, 0, 0, 6, 6, 6, 6, 0, 0, 0, 0, 53, 53, 0, 0, 0, 0, 0, 0, 54, 0, 0, 0, 54, 54, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sample in dataset[\"train\"].select(range(3)):\n",
    "    print(sample)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'art', 'building', 'event', 'location', 'organization', 'other', 'person', 'product']\n"
     ]
    }
   ],
   "source": [
    "# inspect labels\n",
    "labels = dataset[\"train\"].features[\"ner_tags\"].feature.names\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset that consists of examples with `Person` entity only\n",
    "\n",
    "**Note** - Exactly half of the examples in each split contain Person entities, while other half don't have any. This is to help with diversity of training data and model generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import ClassLabel, Features, Sequence, Value\n",
    "\n",
    "\n",
    "FEATURES = Features(\n",
    "    {\n",
    "        \"tokens\": Sequence(feature=Value(dtype=\"string\")),\n",
    "        \"ner_tags\": Sequence(feature=ClassLabel(names=[\"O\", \"B-PER\", \"I-PER\"])),\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "def get_fewnerd(entity_idx):\n",
    "    \"\"\"Loads FewNERD dataset and reformats labels to only include those for the specified entity.\n",
    "\n",
    "    Args:\n",
    "        entity_idx (int): The index of the entity from FewNERD dataset to keep.\n",
    "\n",
    "    Returns:\n",
    "        dataset: The filtered dataset containing `ner_tags` for only the specified entity.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def mapper(sample):\n",
    "        sample[\"ner_tags\"] = [int(tag == entity_idx) for tag in sample[\"ner_tags\"]]\n",
    "        sample[\"ner_tags\"] = [\n",
    "            2 if tag == 1 and idx > 0 and sample[\"ner_tags\"][idx - 1] == 1 else tag\n",
    "            for idx, tag in enumerate(sample[\"ner_tags\"])\n",
    "        ]\n",
    "        return sample\n",
    "\n",
    "    dataset = load_dataset(\"DFKI-SLT/few-nerd\", \"supervised\")\n",
    "    dataset = dataset.map(mapper, remove_columns=[\"id\", \"fine_ner_tags\"])\n",
    "    dataset = dataset.cast(FEATURES)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3579355ba4ff4be8a01039c591e1f440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/131767 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ccd7949deea49d098dce87048c8e274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18824 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8eb6b104a54bd8b718a72fedda27c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/37648 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6785442c924064a1893e7e73b0ba8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/131767 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "839fe272815047e2948e51c7c64c2d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/18824 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d06ef25853d4a80b487aa0c6a29204a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/37648 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 131767\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 18824\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 37648\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fewnerd_dataset = get_fewnerd(7)\n",
    "fewnerd_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datasets import concatenate_datasets, DatasetDict, Dataset\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "def has_person(sample):\n",
    "    return bool(sum(sample[\"ner_tags\"]))\n",
    "\n",
    "\n",
    "def has_no_person(sample):\n",
    "    return not has_person(sample)\n",
    "\n",
    "\n",
    "def preprocess_raw_dataset(raw_dataset):\n",
    "    \"\"\"\n",
    "    Preprocesses the raw dataset by filtering out examples that do not contain a person entity,\n",
    "    balancing the dataset by randomly selecting and including examples without a person entity,\n",
    "    and concatenating the filtered datasets.\n",
    "\n",
    "    Args:\n",
    "        raw_dataset (Dataset): The raw dataset to be preprocessed.\n",
    "\n",
    "    Returns:\n",
    "        Dataset: The preprocessed dataset.\n",
    "    \"\"\"\n",
    "    dataset_person = raw_dataset.filter(has_person)\n",
    "    dataset_no_person = raw_dataset.filter(has_no_person)\n",
    "    dataset_no_person = dataset_no_person.select(\n",
    "        random.sample(range(len(dataset_no_person)), k=len(dataset_person))\n",
    "    )\n",
    "    dataset = concatenate_datasets([dataset_person, dataset_no_person])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c9d62092814e9884e10836748585a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/131767 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2034a288d68746e580b6b4e1310fa4fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/131767 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce9288b0014a41879d9dc7c0cfd74c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/37648 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3aa4b8a68e40479417070c8998431f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/37648 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f937c797de254cbf87f2045072f10c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/18824 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d697119f4f42179ec50515fd25b384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/18824 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 85524\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 12546\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 24422\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare dataset\n",
    "processed_fewnerd_train = preprocess_raw_dataset(fewnerd_dataset[\"train\"])\n",
    "processed_fewnerd_test = preprocess_raw_dataset(fewnerd_dataset[\"test\"])\n",
    "processed_fewnerd_val = preprocess_raw_dataset(fewnerd_dataset[\"validation\"])\n",
    "\n",
    "processed_dataset_dict = DatasetDict(\n",
    "    {\n",
    "        \"train\": processed_fewnerd_train,\n",
    "        \"validation\": processed_fewnerd_val,\n",
    "        \"test\": processed_fewnerd_test,\n",
    "    }\n",
    ")\n",
    "processed_dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['It', 'starred', 'Hicks', \"'s\", 'wife', ',', 'Ellaline', 'Terriss', 'and', 'Edmund', 'Payne', '.'], 'ner_tags': [0, 0, 1, 0, 0, 0, 1, 2, 0, 1, 2, 0]}\n",
      "\n",
      "{'tokens': ['``', 'Time', '``', 'magazine', 'said', 'the', 'film', 'was', '``', 'a', 'multimillion', 'dollar', 'improvisation', 'that', 'does', 'everything', 'but', 'what', 'the', 'title', 'promises', \"''\", 'and', 'suggested', 'that', '``', 'writer', 'George', 'Axelrod', '(', '``', 'The', 'Seven', 'Year', 'Itch', '``', ')', 'and', 'director', 'Richard', 'Quine', 'should', 'have', 'taken', 'a', 'hint', 'from', 'Holden', '[', \"'s\", 'character', 'Richard', 'Benson', ']', ',', 'who', 'writes', 'his', 'movie', ',', 'takes', 'a', 'long', 'sober', 'look', 'at', 'what', 'he', 'has', 'wrought', ',', 'and', 'burns', 'it', '.', \"''\"], 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "\n",
      "{'tokens': ['Imelda', 'de', \"'\", 'Lambertazzi', 'is', 'a', '``', 'melodramma', 'tragico', \"''\", 'or', 'tragic', 'opera', 'in', 'two', 'acts', 'by', 'Gaetano', 'Donizett', 'i', 'from', 'a', 'libretto', 'by', 'Andrea', 'Leone', 'Tottola', ',', 'based', 'on', 'the', 'tragedy', '``', 'Imelda', \"''\", 'by', 'Gabriele', 'Sperduti', '.'], 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "\n",
      "{'tokens': ['In', '1783', 'Campbell', 'married', 'Olympia', 'Elizabeth', '(', 'died', '1794', ')', ',', 'eldest', 'daughter', 'of', 'William', 'Morshead', 'of', 'Cartuther', ',', 'Cornwall', '.'], 'ner_tags': [0, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0]}\n",
      "\n",
      "{'tokens': ['Neville', 'performed', 'a', 'Spinning', 'Back', 'Kick', 'on', 'Tozawa', 'to', 'retain', 'the', 'title', '.'], 'ner_tags': [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]}\n",
      "\n",
      "{'tokens': ['From', 'her', 'locations', 'Mrs.', 'Strong', 'created', 'papers', 'for', 'the', 'Duke', 'of', 'Windsor', 'and', 'Wallis', ',', 'The', 'Duchess', 'of', 'Windsor', ',', 'Barbara', 'Hutton', ',', 'the', 'Rockefeller', ',', 'Astor', ',', 'Vanderbilt', ',', 'and', 'DuPont', 'families', ',', 'as', 'well', 'as', 'Bette', 'Davis', ',', 'Diana', 'Vreeland', ',', 'Jacqueline', 'Bouvier', 'Kennedy', ',', 'Barbara', 'Paley', ',', 'and', 'other', 'icons', 'of', 'style', '.'], 'ner_tags': [0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 2, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0]}\n",
      "\n",
      "{'tokens': ['As', 'a', 'result', 'of', 'outdoing', 'the', 'competition', ',', 'Binion', 'received', 'death', 'threats', ',', 'although', 'eventually', 'casinos', 'raised', 'their', 'limits', 'to', 'keep', 'up', 'with', 'him', '.'], 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "\n",
      "{'tokens': ['During', 'medical', 'school', ',', 'Reitman', 'often', 'worked', 'as', 'the', 'house', 'doctor', 'at', 'sporting', 'events', 'at', 'the', 'Boston', 'Garden', '.'], 'ner_tags': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "\n",
      "{'tokens': ['Formerly', 'known', 'as', 'the', 'Communiplex', ',', 'it', 'is', 'home', 'to', 'the', 'WHL', \"'s\", 'Prince', 'Albert', 'Raiders', 'and', 'the', 'Prince', 'Albert', 'Mintos', '.'], 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0]}\n",
      "\n",
      "{'tokens': ['The', 'chapel', 'of', 'Stalmine', 'was', 'first', 'mentioned', 'about', '1200', 'and', 'a', 'cemetery', 'was', 'consecrated', 'in', '1230', '.'], 'ner_tags': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inspect\n",
    "for sample in processed_dataset_dict[\"train\"].select(range(10)):\n",
    "    print(sample)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment the dataset with additional examples\n",
    "\n",
    "Peoples names often occur as standalone strings rather than just being included in a sentence with contextual information. To improve performance on names occuring in this paradigm, let's create some specific examples to augment our dataset with.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from names_dataset import NameDataset\n",
    "\n",
    "\n",
    "def generate_full_names(n, country_codes):\n",
    "    \"\"\"Creates a list of full names from the top `n` first and last names for each country.\n",
    "\n",
    "    Randomly mixes first and last names.\n",
    "\n",
    "    Uses this library: https://github.com/philipperemy/name-dataset\n",
    "\n",
    "    Args:\n",
    "        n (int): The number of first and last names to use for each country.\n",
    "        country_codes (list): A list of country codes to use.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of full names.\n",
    "    \"\"\"\n",
    "    nd = NameDataset()\n",
    "    full_names = []\n",
    "    for code in country_codes:\n",
    "        first_names = nd.get_top_names(n=math.ceil(n / 2), country_alpha2=code)[code]\n",
    "        first_names = first_names[\"M\"] + first_names[\"F\"]\n",
    "\n",
    "        last_names = nd.get_top_names(n=n, country_alpha2=code, use_first_names=False)[\n",
    "            code\n",
    "        ]\n",
    "\n",
    "        random.seed(42)\n",
    "        random.shuffle(first_names)\n",
    "        random.shuffle(last_names)\n",
    "\n",
    "        if len(first_names) != len(last_names):\n",
    "            first_names = first_names[: len(last_names)]\n",
    "\n",
    "        full_names += [\n",
    "            f\"{first} {last}\" for first, last in zip(first_names, last_names)\n",
    "        ]\n",
    "\n",
    "    return full_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_names_dataset():\n",
    "    \"\"\"\n",
    "    Builds a dataset of names with tokenization and annotation.\n",
    "\n",
    "    Returns:\n",
    "        names_dataset (Dataset): A dataset containing tokenized and annotated names.\n",
    "    \"\"\"\n",
    "\n",
    "    def tokenize_and_annotate_names(example):\n",
    "        example[\"tokens\"] = example[\"text\"].split(\" \")\n",
    "        example[\"ner_tags\"] = [\n",
    "            1 if idx == 0 else 2 for idx, _ in enumerate(example[\"tokens\"])\n",
    "        ]\n",
    "        return example\n",
    "\n",
    "    # generate list of full names\n",
    "    nd = NameDataset()\n",
    "    country_codes = [country.alpha_2 for country in nd.get_country_codes()]\n",
    "    sample_names = generate_full_names(500, country_codes=country_codes)\n",
    "    random.shuffle(sample_names)\n",
    "\n",
    "    # create HF dataset with required features\n",
    "    names_dataset = Dataset.from_dict({\"text\": sample_names})\n",
    "    names_dataset = names_dataset.map(\n",
    "        tokenize_and_annotate_names, remove_columns=[\"text\"]\n",
    "    )\n",
    "    names_dataset = names_dataset.cast(FEATURES)\n",
    "\n",
    "    return names_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ee6a22c2e74083b26fe51546b0926b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52472 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f3c065e04b4812b44517c5e62fc6f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/52472 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names_dataset = build_names_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['Ð’Ð¸ÐºÑ‚Ð¾Ñ€', 'Sochirca'], 'ner_tags': [1, 2]}\n",
      "\n",
      "{'tokens': ['Hugo', 'Inacio'], 'ner_tags': [1, 2]}\n",
      "\n",
      "{'tokens': ['Fransiska', 'Manalu'], 'ner_tags': [1, 2]}\n",
      "\n",
      "{'tokens': ['Mark', 'Danladi'], 'ner_tags': [1, 2]}\n",
      "\n",
      "{'tokens': ['Nilima', 'Bappy'], 'ner_tags': [1, 2]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sample in names_dataset.select(range(5)):\n",
    "    print(sample)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_dataset_traintest = names_dataset.train_test_split(test_size=0.3, seed=42)\n",
    "names_dataset_val = names_dataset_traintest[\"test\"].train_test_split(\n",
    "    test_size=0.5, seed=42\n",
    ")\n",
    "\n",
    "names_dataset_dict = DatasetDict(\n",
    "    {\n",
    "        \"train\": names_dataset_traintest[\"train\"],\n",
    "        \"validation\": names_dataset_val[\"train\"],\n",
    "        \"test\": names_dataset_val[\"test\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "full_dataset_dict = DatasetDict()\n",
    "for key in processed_dataset_dict.keys():\n",
    "    full_dataset_dict[key] = concatenate_datasets(\n",
    "        [processed_dataset_dict[key], names_dataset_dict[key]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 122254\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 20417\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 32293\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842772275bf1455ca47eb3a113f8d220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bdc2e5bcd2344e9bac8f6bc1460125e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/123 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7465d72999b4e88b94ad099ca56b49f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e84b0ec4f90c4b9491cfd1ec523f42c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83eec8d044164a1eb25195e6ebfa54ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "224cc62c4bb74545a77c6f8ca7a73fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/andrewrreed/fewnerd-person-names-augmented/commit/b55ac0adfaf5276d3dbb3071b7bd44939593f834', commit_message='Upload dataset', commit_description='', oid='b55ac0adfaf5276d3dbb3071b7bd44939593f834', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset_dict.push_to_hub(\"andrewrreed/fewnerd-person-names-augmented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additional thoughts on data curation for future work**\n",
    "- It might be good to include some short phrases of a 1-5 tokens that are NOT Person entities. This will force the model to not assume every 2-3 word string is a name.... reducing false positives\n",
    "- With a large list of diverse names, you could also experiment with generating synthetic data with an LLM that inserts that name into a random sentence. This would improve diversity and number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SpanMarker NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train_spanmarker.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_spanmarker.py\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import shutil\n",
    "from datasets import load_dataset, concatenate_datasets, Features, Sequence, ClassLabel, Value, DatasetDict\n",
    "from transformers import TrainingArguments\n",
    "from span_marker import SpanMarkerModel, Trainer\n",
    "from span_marker.model_card import SpanMarkerModelCardData\n",
    "from huggingface_hub import upload_folder, upload_file\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"]=\"spanmarker-ner-single-entity\"\n",
    "\n",
    "def main() -> None:\n",
    "    # Load the dataset, ensure \"tokens\" and \"ner_tags\" columns, and get a list of labels\n",
    "    labels = [\"O\", \"B-PER\", \"I-PER\"]\n",
    "    dataset_id = \"andrewrreed/fewnerd-person-names-augmented\"\n",
    "    dataset = load_dataset(dataset_id)\n",
    "\n",
    "    train_dataset = dataset[\"train\"]\n",
    "    test_dataset = dataset[\"test\"]\n",
    "    val_dataset = dataset[\"validation\"]\n",
    "\n",
    "    # Initialize a SpanMarker model using a pretrained ROBERTA-style encoder\n",
    "    encoder_id = \"roberta-base\"\n",
    "    model_id = \"andrewrreed/span-marker-roberta-base-person-names-augmented\"\n",
    "    model = SpanMarkerModel.from_pretrained(\n",
    "        encoder_id,\n",
    "        labels=labels,\n",
    "        # SpanMarker hyperparameters:\n",
    "        model_max_length=512,\n",
    "        marker_max_length=128,\n",
    "        entity_max_length=8,\n",
    "        # Model card variables\n",
    "        model_card_data=SpanMarkerModelCardData(\n",
    "            model_id=model_id,\n",
    "            dataset_id=dataset_id,\n",
    "            encoder_id=encoder_id,\n",
    "            license=\"cc-by-sa-4.0\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Prepare the ðŸ¤— transformers training arguments\n",
    "    output_dir = Path(\"models\") / model_id\n",
    "    args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        run_name=model_id,\n",
    "        # Training Hyperparameters:\n",
    "        learning_rate=5e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        warmup_ratio=0.1,\n",
    "        bf16=True,  # Replace `bf16` with `fp16` if your hardware can't use bf16.\n",
    "        # Other Training parameters\n",
    "        logging_first_step=True,\n",
    "        logging_steps=200,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=1000,\n",
    "        eval_steps=1000,\n",
    "        load_best_model_at_end=True,\n",
    "        save_total_limit=3,\n",
    "        dataloader_num_workers=4,\n",
    "        report_to=\"wandb\",\n",
    "    )\n",
    "\n",
    "    # Initialize the trainer using our model, training args & dataset, and train\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "    # Compute & save the metrics on the val set\n",
    "    metrics = trainer.evaluate(val_dataset, metric_key_prefix=\"val\")\n",
    "    trainer.save_metrics(\"val\", metrics)\n",
    "\n",
    "    # Save the model & training script locally\n",
    "    trainer.save_model(output_dir / \"checkpoint-final\")\n",
    "    shutil.copy2(__file__, output_dir / \"checkpoint-final\" / \"train.py\")\n",
    "\n",
    "    # Upload everything to the Hub\n",
    "    model.push_to_hub(model_id, private=True)\n",
    "    upload_file(path_or_fileobj=output_dir / \"all_results.json\", path_in_repo=\"all_results.json\", repo_id=model_id)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After executing the above cell, you can run that script via command line to train model and save checkpoints: `python train_spanmarker.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model and compare to reference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from span_marker import SpanMarkerModel, Trainer\n",
    "from datasets import (\n",
    "    load_dataset,\n",
    ")\n",
    "\n",
    "# Load the dataset\n",
    "dataset_id = \"andrewrreed/fewnerd-person-names-augmented\"\n",
    "dataset = load_dataset(dataset_id)\n",
    "\n",
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]\n",
    "val_dataset = dataset[\"validation\"]\n",
    "\n",
    "# load model + trainer\n",
    "model_id = \"andrewrreed/span-marker-roberta-base-person-names-augmented\"\n",
    "model = SpanMarkerModel.from_pretrained(model_id)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'holdout_loss': 0.0016791035886853933,\n",
       " 'holdout_PER': {'precision': 0.9512027491408934,\n",
       "  'recall': 0.9548373401263068,\n",
       "  'f1': 0.9530165792679697,\n",
       "  'number': 18843},\n",
       " 'holdout_overall_precision': 0.9512027491408934,\n",
       " 'holdout_overall_recall': 0.9548373401263068,\n",
       " 'holdout_overall_f1': 0.9530165792679697,\n",
       " 'holdout_overall_accuracy': 0.9929037259180112,\n",
       " 'holdout_runtime': 241.3287,\n",
       " 'holdout_samples_per_second': 87.632,\n",
       " 'holdout_steps_per_second': 10.956}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics = trainer.evaluate(val_dataset, metric_key_prefix=\"holdout\")\n",
    "val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKENS:  ['The', 'Jiribam', 'rail', 'ink', 'was', 'a', 'part', 'of', 'rail', 'link', 'to', 'Assam', 'for', 'tea', 'transportation', 'in', 'the', 'early', '20th', 'century', '.']\n",
      "GOLD:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "PRED:  []\n",
      "\n",
      "TOKENS:  ['Sciberras', 'Sciriha']\n",
      "GOLD:  [1, 2]\n",
      "PRED:  [{'span': ['Sciberras', 'Sciriha'], 'label': 'PER', 'score': 0.9999983310699463, 'word_start_index': 0, 'word_end_index': 2}]\n",
      "\n",
      "TOKENS:  ['The', 'Centre', 'contains', 'classrooms', ',', 'labs', ',', 'administrative', 'offices', ',', 'dining', 'hall', ',', 'kitchen', ',', 'and', 'conference', 'room', '.']\n",
      "GOLD:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "PRED:  []\n",
      "\n",
      "TOKENS:  ['One', 'fourth', 'of', 'Jackson', 'County', 'is', 'Daniel', 'Boone', 'National', 'Forest', '(', '56,000', 'acres', ')', ',', 'making', 'it', 'representative', 'of', 'Eastern', 'Kentucky', \"'s\", 'unique', 'Appalachian', 'topography', ',', 'wildlife', ',', 'and', 'heritage', '.']\n",
      "GOLD:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "PRED:  []\n",
      "\n",
      "TOKENS:  ['In', 'the', 'second', 'quarter', ',', 'the', 'Jaguars', 'drove', '72', 'yards', 'to', 'the', 'Titans', '5-yard', 'line', ',', 'only', 'to', 'have', 'Brunell', 'throw', 'an', 'interception', 'to', 'safety', 'Marcus', 'Robertson', 'in', 'the', 'end', 'zone', '.']\n",
      "GOLD:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0]\n",
      "PRED:  [{'span': ['Brunell'], 'label': 'PER', 'score': 0.9761291742324829, 'word_start_index': 19, 'word_end_index': 20}, {'span': ['Marcus', 'Robertson'], 'label': 'PER', 'score': 0.9867772459983826, 'word_start_index': 25, 'word_end_index': 27}]\n",
      "\n",
      "TOKENS:  ['Another', 'pro', 'wrestler', ',', 'Larry', 'Zbyszko', ',', 'used', '``', 'City', 'To', 'City', '``', 'as', 'his', 'theme', 'music', 'in', 'New', 'Japan', '.']\n",
      "GOLD:  [0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "PRED:  [{'span': ['Larry', 'Zbyszko'], 'label': 'PER', 'score': 0.9967268705368042, 'word_start_index': 4, 'word_end_index': 6}]\n",
      "\n",
      "TOKENS:  ['Abbot', 'also', 'operated', 'near', 'Antarctica', ',', 'assuming', 'command', 'of', 'the', 'US', 'Naval', 'Support', 'Force', ',', 'Antarctica', ',', 'in', 'February', '1967', '.']\n",
      "GOLD:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "PRED:  [{'span': ['Abbot'], 'label': 'PER', 'score': 0.9136765599250793, 'word_start_index': 0, 'word_end_index': 1}]\n",
      "\n",
      "TOKENS:  ['Ecleo', 'is', 'the', 'youngest', 'daughter', 'of', 'the', 'late', 'Supreme', 'President', 'of', 'P.B.M.A', '&', 'amp', ';', 'the', 'former', 'longest', 'running', 'Mayor', 'of', 'Dinagat', 'Islands', ',', 'Ruben', 'Edera', 'Ecleo', ',', 'Sr.', 'and', 'Glenda', 'B.', 'Ecleo', ',', 'the', 'former', 'Congresswoman', 'who', 'is', 'now', 'the', 'Governor', 'of', 'the', 'province', 'of', 'Dinagat', 'Islands', '.']\n",
      "GOLD:  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "PRED:  [{'span': ['Ecleo'], 'label': 'PER', 'score': 0.986151397228241, 'word_start_index': 0, 'word_end_index': 1}, {'span': ['Ruben', 'Edera', 'Ecleo'], 'label': 'PER', 'score': 0.9869794845581055, 'word_start_index': 24, 'word_end_index': 27}, {'span': ['Glenda', 'B.', 'Ecleo'], 'label': 'PER', 'score': 0.9858275651931763, 'word_start_index': 30, 'word_end_index': 33}]\n",
      "\n",
      "TOKENS:  ['He', 'is', 'the', 'James', 'D.', 'Wolfensohn', 'Professor', 'of', 'Social', 'Science', 'at', 'the', 'Institute', 'for', 'Advanced', 'Study', 'in', 'Princeton', 'and', 'holds', 'a', 'Direction', 'of', 'Studies', 'in', 'Political', 'and', 'Moral', 'Anthropology', 'at', 'the', 'Ã‰cole', 'des', 'Hautes', 'Ã‰tudes', 'en', 'Sciences', 'Sociales', 'in', 'Paris', '.']\n",
      "GOLD:  [0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "PRED:  [{'span': ['James', 'D.', 'Wolfensohn'], 'label': 'PER', 'score': 0.66888028383255, 'word_start_index': 3, 'word_end_index': 6}]\n",
      "\n",
      "TOKENS:  ['In', 'Bamyan', ',', 'a', 'protest', 'gathering', 'for', 'Arman', 'was', 'held', 'on', 'February', '14', 'in', 'front', 'of', 'the', 'Buddhas', 'of', 'Bamyan', 'to', 'condemn', 'his', 'murder', '.']\n",
      "GOLD:  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "PRED:  [{'span': ['Arman'], 'label': 'PER', 'score': 0.8749346137046814, 'word_start_index': 7, 'word_end_index': 8}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inspect some examples\n",
    "sample = val_dataset.shuffle().select(range(10))\n",
    "preds = model.predict(sample[\"tokens\"])\n",
    "\n",
    "for i, ex in enumerate(sample):\n",
    "    print(\"TOKENS: \", ex[\"tokens\"])\n",
    "    print(\"GOLD: \", ex[\"ner_tags\"])\n",
    "    print(\"PRED: \", preds[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate reference model\n",
    "\n",
    "`Davlan/distilbert-base-multilingual-cased-ner-hrl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import evaluator\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "ref_model_id = \"Davlan/distilbert-base-multilingual-cased-ner-hrl\"\n",
    "ref_tokenizer = AutoTokenizer.from_pretrained(ref_model_id)\n",
    "ref_model = AutoModelForTokenClassification.from_pretrained(ref_model_id)\n",
    "task_evaluator = evaluator(\"token-classification\")\n",
    "\n",
    "ref_metrics = task_evaluator.compute(\n",
    "    model_or_pipeline=ref_model,\n",
    "    tokenizer=ref_tokenizer,\n",
    "    data=val_dataset,\n",
    "    metric=\"seqeval\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpanMarker</th>\n",
       "      <th>Reference Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.951203</td>\n",
       "      <td>0.871950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.954837</td>\n",
       "      <td>0.864777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.953017</td>\n",
       "      <td>0.868349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>18843.000000</td>\n",
       "      <td>18843.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             SpanMarker  Reference Model\n",
       "precision      0.951203         0.871950\n",
       "recall         0.954837         0.864777\n",
       "f1             0.953017         0.868349\n",
       "number     18843.000000     18843.000000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\"SpanMarker\": val_metrics[\"holdout_PER\"], \"Reference Model\": ref_metrics[\"PER\"]}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
