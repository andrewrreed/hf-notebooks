{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying Mixtral on AWS Inferentia2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Spin up an EC2 instance\n",
    "\n",
    "Here we'll be using:\n",
    "- [Hugging Face Neuron Deep Learning AMI](https://aws.amazon.com/marketplace/pp/prodview-gr3e6yiscria2)\n",
    "- `ml.inf2.24xlarge` instance type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert `Mixtral-8x7B-Instruct-v0.1` to AWS Neuron with `optimum-neuron`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: ipywidgets in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (8.1.2)\n",
      "Requirement already satisfied: optimum[neuronx] in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (1.18.1)\n",
      "Requirement already satisfied: coloredlogs in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from optimum[neuronx]) (15.0.1)\n",
      "Requirement already satisfied: sympy in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from optimum[neuronx]) (1.12)\n",
      "Requirement already satisfied: transformers<4.40.0,>=4.26.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from transformers[sentencepiece]<4.40.0,>=4.26.0->optimum[neuronx]) (4.36.2)\n",
      "Requirement already satisfied: torch>=1.11 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from optimum[neuronx]) (2.1.2)\n",
      "Requirement already satisfied: packaging in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from optimum[neuronx]) (21.3)\n",
      "Requirement already satisfied: numpy in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from optimum[neuronx]) (1.24.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from optimum[neuronx]) (0.22.2)\n",
      "Requirement already satisfied: datasets in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from optimum[neuronx]) (2.19.1)\n",
      "Requirement already satisfied: optimum-neuron>=0.0.20 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.0.22)\n",
      "Requirement already satisfied: filelock in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from transformers<4.40.0,>=4.26.0->transformers[sentencepiece]<4.40.0,>=4.26.0->optimum[neuronx]) (3.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from transformers<4.40.0,>=4.26.0->transformers[sentencepiece]<4.40.0,>=4.26.0->optimum[neuronx]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from transformers<4.40.0,>=4.26.0->transformers[sentencepiece]<4.40.0,>=4.26.0->optimum[neuronx]) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from transformers<4.40.0,>=4.26.0->transformers[sentencepiece]<4.40.0,>=4.26.0->optimum[neuronx]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from transformers<4.40.0,>=4.26.0->transformers[sentencepiece]<4.40.0,>=4.26.0->optimum[neuronx]) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from transformers<4.40.0,>=4.26.0->transformers[sentencepiece]<4.40.0,>=4.26.0->optimum[neuronx]) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from transformers<4.40.0,>=4.26.0->transformers[sentencepiece]<4.40.0,>=4.26.0->optimum[neuronx]) (4.66.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipywidgets) (8.12.3)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipywidgets) (5.14.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from huggingface-hub>=0.8.0->optimum[neuronx]) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from huggingface-hub>=0.8.0->optimum[neuronx]) (4.10.0)\n",
      "Requirement already satisfied: backcall in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: accelerate==0.23.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from optimum-neuron>=0.0.20->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.23.0)\n",
      "Requirement already satisfied: protobuf<4 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from optimum-neuron>=0.0.20->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (3.19.6)\n",
      "Requirement already satisfied: psutil in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from accelerate==0.23.0->optimum-neuron>=0.0.20->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (5.9.8)\n",
      "Requirement already satisfied: wheel in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.43.0)\n",
      "Requirement already satisfied: neuronx-cc==2.13.66.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (2.13.66.0+6dfecc895)\n",
      "Requirement already satisfied: torch-neuronx==2.1.2.2.1.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (2.1.2.2.1.0)\n",
      "Requirement already satisfied: transformers-neuronx==0.10.0.21 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.10.0.21)\n",
      "Requirement already satisfied: torchvision==0.16.* in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.16.2)\n",
      "Requirement already satisfied: neuronx-distributed==0.7.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.7.0)\n",
      "Requirement already satisfied: networkx in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from torch>=1.11->optimum[neuronx]) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from torch>=1.11->optimum[neuronx]) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from torch>=1.11->optimum[neuronx]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from torch>=1.11->optimum[neuronx]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from torch>=1.11->optimum[neuronx]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from torch>=1.11->optimum[neuronx]) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from torch>=1.11->optimum[neuronx]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from torch>=1.11->optimum[neuronx]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from torch>=1.11->optimum[neuronx]) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from torch>=1.11->optimum[neuronx]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from torch>=1.11->optimum[neuronx]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from torch>=1.11->optimum[neuronx]) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from torch>=1.11->optimum[neuronx]) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from torch>=1.11->optimum[neuronx]) (2.1.0)\n",
      "Requirement already satisfied: scipy<=1.11.2 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from neuronx-cc==2.13.66.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (1.10.1)\n",
      "Requirement already satisfied: python-daemon>=2.2.4 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from neuronx-cc==2.13.66.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (3.0.1)\n",
      "Requirement already satisfied: requests-unixsocket>=0.1.5 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from neuronx-cc==2.13.66.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.3.0)\n",
      "Requirement already satisfied: islpy<=2023.1,>2021.1 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from neuronx-cc==2.13.66.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (2023.1)\n",
      "Requirement already satisfied: pgzip>=0.3.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from neuronx-cc==2.13.66.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.3.5)\n",
      "Requirement already satisfied: ec2-metadata<=2.10.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from neuronx-cc==2.13.66.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (2.10.0)\n",
      "Requirement already satisfied: torch-xla in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from neuronx-distributed==0.7.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (2.1.2)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11->optimum[neuronx]) (12.4.127)\n",
      "Requirement already satisfied: libneuronxla<3.0,>2.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from torch-neuronx==2.1.2.2.1.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (2.0.965)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from torchvision==0.16.*->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (10.3.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from torch-xla->neuronx-distributed==0.7.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (2.1.0)\n",
      "Requirement already satisfied: cloud-tpu-client>=0.10.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from torch-xla->neuronx-distributed==0.7.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.10)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from packaging->optimum[neuronx]) (3.1.2)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from transformers[sentencepiece]<4.40.0,>=4.26.0->optimum[neuronx]) (0.2.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from coloredlogs->optimum[neuronx]) (10.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from datasets->optimum[neuronx]) (16.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from datasets->optimum[neuronx]) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from datasets->optimum[neuronx]) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from datasets->optimum[neuronx]) (2.0.3)\n",
      "Requirement already satisfied: xxhash in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from datasets->optimum[neuronx]) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from datasets->optimum[neuronx]) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from datasets->optimum[neuronx]) (3.9.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from sympy->optimum[neuronx]) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from aiohttp->datasets->optimum[neuronx]) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from aiohttp->datasets->optimum[neuronx]) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from aiohttp->datasets->optimum[neuronx]) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from aiohttp->datasets->optimum[neuronx]) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from aiohttp->datasets->optimum[neuronx]) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from aiohttp->datasets->optimum[neuronx]) (4.0.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from requests->transformers<4.40.0,>=4.26.0->transformers[sentencepiece]<4.40.0,>=4.26.0->optimum[neuronx]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from requests->transformers<4.40.0,>=4.26.0->transformers[sentencepiece]<4.40.0,>=4.26.0->optimum[neuronx]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from requests->transformers<4.40.0,>=4.26.0->transformers[sentencepiece]<4.40.0,>=4.26.0->optimum[neuronx]) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from requests->transformers<4.40.0,>=4.26.0->transformers[sentencepiece]<4.40.0,>=4.26.0->optimum[neuronx]) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from jinja2->torch>=1.11->optimum[neuronx]) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from pandas->datasets->optimum[neuronx]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from pandas->datasets->optimum[neuronx]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from pandas->datasets->optimum[neuronx]) (2024.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: aws-neuronx-runtime-discovery~=2.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from libneuronxla<3.0,>2.0->torch-neuronx==2.1.2.2.1.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (2.9)\n",
      "Requirement already satisfied: boto3 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from libneuronxla<3.0,>2.0->torch-neuronx==2.1.2.2.1.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (1.34.75)\n",
      "Requirement already satisfied: botocore in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from libneuronxla<3.0,>2.0->torch-neuronx==2.1.2.2.1.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (1.34.75)\n",
      "Requirement already satisfied: docutils in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from python-daemon>=2.2.4->neuronx-cc==2.13.66.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.16)\n",
      "Requirement already satisfied: lockfile>=0.10 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from python-daemon>=2.2.4->neuronx-cc==2.13.66.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.12.2)\n",
      "Requirement already satisfied: setuptools>=62.4.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from python-daemon>=2.2.4->neuronx-cc==2.13.66.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (69.2.0)\n",
      "Requirement already satisfied: google-api-python-client==1.8.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from cloud-tpu-client>=0.10.0->torch-xla->neuronx-distributed==0.7.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (1.8.0)\n",
      "Requirement already satisfied: oauth2client in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from cloud-tpu-client>=0.10.0->torch-xla->neuronx-distributed==0.7.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (4.1.3)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla->neuronx-distributed==0.7.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.22.0)\n",
      "Requirement already satisfied: google-auth>=1.4.1 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla->neuronx-distributed==0.7.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (2.29.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla->neuronx-distributed==0.7.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.2.0)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla->neuronx-distributed==0.7.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (1.34.1)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla->neuronx-distributed==0.7.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (3.0.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from boto3->libneuronxla<3.0,>2.0->torch-neuronx==2.1.2.2.1.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from boto3->libneuronxla<3.0,>2.0->torch-neuronx==2.1.2.2.1.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.10.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch-xla->neuronx-distributed==0.7.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.6.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch-xla->neuronx-distributed==0.7.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.4.0)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch-xla->neuronx-distributed==0.7.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (4.7.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla->neuronx-distributed==0.7.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (1.63.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla->neuronx-distributed==0.7.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (5.3.3)\n"
     ]
    }
   ],
   "source": [
    "# optimium[neuronx] comes pre-installed, but upgrade to latest: \n",
    "# https://huggingface.co/docs/optimum-neuron/installation\n",
    "!pip install --upgrade-strategy eager optimum[neuronx] ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
      "    Setting a new token will erase the existing one.\n",
      "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /home/ubuntu/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# login for gated repo\n",
    "from huggingface_hub import interpreter_login\n",
    "\n",
    "interpreter_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** The Mixtral implementation in `aws-neuron/transformers-neuronx` has [a requirement](https://github.com/aws-neuron/transformers-neuronx/blob/0623de20a3934f8d1b3cb73e1672138657134d7f/src/transformers_neuronx/mixtral/config.py#L57) on the value for `tp_degree`. \n",
    "- `tp_degree` is [auto-populated](https://github.com/huggingface/optimum-neuron/blob/7439a2d32808ce19ddece2d9a34d047af46dd1b1/optimum/neuron/modeling_decoder.py#L174) in `optimum-neuron` to be equal to `num_cores`.\n",
    "- For this reason, you can only compile the model with the `num_cores` set to 8 or 16 (32 is only for tranium instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5648428ddadd473ca37fe4268e731d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-21 19:38:41.000650:  20050  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-May-21 19:40:11.264821 20050:20050 ERROR  TDRV:dmem_alloc_internal                     Failed to alloc DEVICE memory: 117440512\n",
      "2024-May-21 19:40:11.389363 20050:20050 ERROR  TDRV:dml_dump                                Wrote nrt memory alloc debug info to /tmp/nrt_mem_log_device_0_664cf89b.csv\n",
      "2024-May-21 19:40:11.560334 20050:20050 ERROR  TDRV:log_dev_mem                             Failed to allocate 112.000MB (usage: tensors) on ND 0:NC 0, current utilization:\n",
      "\t* total: 15.903GB\n",
      "\t* tensors: 15.903GB\n",
      "\t* runtime: 1.062KB\n",
      "\t* dma rings: 32.000KB\n",
      "\n",
      "2024-May-21 19:40:11.888299 20050:20050 ERROR  TDRV:tensor_allocate                         Failed to allocate 117440512 bytes on DEVICE for tensor UNKNOWN.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "nrt_tensor_allocate status=4 message=\"Allocation Failure\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m\n\u001b[1;32m      8\u001b[0m compiler_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_cores\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m8\u001b[39m , \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_cast_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbf16\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m      9\u001b[0m input_shapes \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     10\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence_length\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m32768\u001b[39m, \u001b[38;5;66;03m# max length to generate\u001b[39;00m\n\u001b[1;32m     11\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# batch size for the model\u001b[39;00m\n\u001b[1;32m     12\u001b[0m   }\n\u001b[0;32m---> 14\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mNeuronModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvanilla_model_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcompiler_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(vanilla_model_id)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Save locally or upload to the HuggingFace Hub\u001b[39;00m\n",
      "File \u001b[0;32m/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/optimum/modeling_base.py:401\u001b[0m, in \u001b[0;36mOptimizedModel.from_pretrained\u001b[0;34m(cls, model_id, export, force_download, use_auth_token, cache_dir, subfolder, config, local_files_only, trust_remote_code, revision, **kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m     trust_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    399\u001b[0m from_pretrained_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_from_transformers \u001b[38;5;28;01mif\u001b[39;00m export \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_from_pretrained\n\u001b[0;32m--> 401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_pretrained_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/optimum/neuron/utils/require_utils.py:50\u001b[0m, in \u001b[0;36m_create_requires_function.<locals>.require_func.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m availability_function():\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires the `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` package. You can install it by running: pip \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstall \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m     )\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/optimum/neuron/modeling_decoder.py:323\u001b[0m, in \u001b[0;36mNeuronDecoderModel._from_transformers\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;129m@requires_transformers_neuronx\u001b[39m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_transformers\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;66;03m# Deprecate it when optimum uses `_export` as from_pretrained_method in a stable release.\u001b[39;00m\n\u001b[0;32m--> 323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/optimum/neuron/utils/require_utils.py:50\u001b[0m, in \u001b[0;36m_create_requires_function.<locals>.require_func.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m availability_function():\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires the `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` package. You can install it by running: pip \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstall \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m     )\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/optimum/neuron/modeling_decoder.py:371\u001b[0m, in \u001b[0;36mNeuronDecoderModel._export\u001b[0;34m(cls, model_id, config, use_auth_token, revision, task, batch_size, sequence_length, num_cores, auto_cast_type, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/optimum/neuron/modeling.py:671\u001b[0m, in \u001b[0;36mNeuronModelForCausalLM.__init__\u001b[0;34m(self, config, checkpoint_dir, compiled_dir, generation_config)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    666\u001b[0m     config: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPretrainedConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    669\u001b[0m     generation_config: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerationConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    670\u001b[0m ):\n\u001b[0;32m--> 671\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompiled_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompiled_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mneuron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mneuron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence_length\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/optimum/neuron/utils/require_utils.py:50\u001b[0m, in \u001b[0;36m_create_requires_function.<locals>.require_func.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m availability_function():\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires the `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` package. You can install it by running: pip \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstall \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m     )\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/optimum/neuron/modeling_decoder.py:215\u001b[0m, in \u001b[0;36mNeuronDecoderModel.__init__\u001b[0;34m(self, config, checkpoint_dir, compiled_dir, generation_config)\u001b[0m\n\u001b[1;32m    212\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNEURON_RT_NUM_CORES\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(num_cores)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# Load the model on neuron cores (if found in cache or compiled directory, the NEFF files\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# will be reloaded instead of compiled)\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m \u001b[43mneuronx_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_neuron\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m neuron_rt_num_cores \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNEURON_RT_NUM_CORES\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/transformers_neuronx/base.py:68\u001b[0m, in \u001b[0;36mNeuronModelBase.to_neuron\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_neuron\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_compiled_artifacts_directory\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_compiled_artifacts(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_artifacts_directory)\n",
      "File \u001b[0;32m/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/transformers_neuronx/mixtral/model.py:118\u001b[0m, in \u001b[0;36mMixtralForSampling.load_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m     new_layer\u001b[38;5;241m.\u001b[39madd_parameter(w2_concat, sharding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, allow_pad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# down_proj\u001b[39;00m\n\u001b[1;32m    113\u001b[0m                             allow_quantize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    114\u001b[0m     new_layer\u001b[38;5;241m.\u001b[39madd_parameter(w3_concat, sharding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, allow_pad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# up_proj\u001b[39;00m\n\u001b[1;32m    115\u001b[0m                             allow_quantize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 118\u001b[0m     \u001b[43mnew_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_neuron\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     layer\u001b[38;5;241m.\u001b[39mnullify()\n\u001b[1;32m    121\u001b[0m ln_f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchkpt_model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnorm\n",
      "File \u001b[0;32m/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/transformers_neuronx/decoder.py:1125\u001b[0m, in \u001b[0;36mDecoderLayer.to_neuron\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         scales \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_transform:\n\u001b[0;32m-> 1125\u001b[0m     param \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_shard_along_and_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1127\u001b[0m     param \u001b[38;5;241m=\u001b[39m maybe_manipulator\u001b[38;5;241m.\u001b[39mduplicate_or_shard_along(param, dim)\n",
      "File \u001b[0;32m/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/transformers_neuronx/decoder.py:1412\u001b[0m, in \u001b[0;36mMaybeParallelTensorManipulator.shard_along_and_transform\u001b[0;34m(self, tensor, dim)\u001b[0m\n\u001b[1;32m   1410\u001b[0m tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanipulator\u001b[38;5;241m.\u001b[39mshard_along_on_cpu(tensor, dim)\n\u001b[1;32m   1411\u001b[0m tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_and_tile_weight_layout(tensors)\n\u001b[0;32m-> 1412\u001b[0m tensor \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_to_nc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1413\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/transformers_neuronx/ops.py:49\u001b[0m, in \u001b[0;36mparallel_to_nc\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_to_nc\u001b[39m(tensors):\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneuron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parallel_to_neuron\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/torch/_ops.py:692\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: nrt_tensor_allocate status=4 message=\"Allocation Failure\""
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from optimum.neuron import NeuronModelForCausalLM\n",
    "\n",
    "# model id you want to compile\n",
    "vanilla_model_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "\n",
    "# configs for compiling model\n",
    "compiler_args = {\"num_cores\": 8 , \"auto_cast_type\": \"bf16\"}\n",
    "input_shapes = {\n",
    "  \"sequence_length\": 32768, # max length to generate\n",
    "  \"batch_size\": 1 # batch size for the model\n",
    "  }\n",
    "\n",
    "llm = NeuronModelForCausalLM.from_pretrained(vanilla_model_id, export=True, **input_shapes, **compiler_args)\n",
    "tokenizer = AutoTokenizer.from_pretrained(vanilla_model_id)\n",
    "\n",
    "# Save locally or upload to the HuggingFace Hub\n",
    "save_directory = \"./mixtral_neuron2\"\n",
    "llm.save_pretrained(save_directory)\n",
    "tokenizer.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "047c4536fd2e403bba815f11ce98ee39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-21 16:43:38.000891:  20050  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-05-21 16:49:44.000719:  20650  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-05-21 16:49:44.000807:  20651  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "neuronxcc-2.13.66.0+6dfecc895/MODULE_0ee6a82628ec518e67cf+2c2d707e/model.neff not found in aws-neuron/optimum-neuron-cache: the corresponding graph will be recompiled. This may take up to one hour for large models.\n",
      "neuronxcc-2.13.66.0+6dfecc895/MODULE_0ee6a82628ec518e67cf+2c2d707e/model.neff not found in aws-neuron/optimum-neuron-cache: the corresponding graph will be recompiled. This may take up to one hour for large models.\n",
      "neuronxcc-2.13.66.0+6dfecc895/MODULE_e899a005793b73bcce61+2c2d707e/model.neff not found in aws-neuron/optimum-neuron-cache: the corresponding graph will be recompiled. This may take up to one hour for large models.\n",
      "neuronxcc-2.13.66.0+6dfecc895/MODULE_e899a005793b73bcce61+2c2d707e/model.neff not found in aws-neuron/optimum-neuron-cache: the corresponding graph will be recompiled. This may take up to one hour for large models.\n",
      "neuronxcc-2.13.66.0+6dfecc895/MODULE_0ee6a82628ec518e67cf+2c2d707e/model.neff not found in aws-neuron/optimum-neuron-cache: the corresponding graph will be recompiled. This may take up to one hour for large models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-21 16:49:45.000179:  20650  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/dd215b5d-e505-476c-9154-4ffa49973022/model.MODULE_0ee6a82628ec518e67cf+2c2d707e.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/dd215b5d-e505-476c-9154-4ffa49973022/model.MODULE_0ee6a82628ec518e67cf+2c2d707e.neff --model-type=transformer --auto-cast=none --verbose=35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "neuronxcc-2.13.66.0+6dfecc895/MODULE_e899a005793b73bcce61+2c2d707e/model.neff not found in aws-neuron/optimum-neuron-cache: the corresponding graph will be recompiled. This may take up to one hour for large models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-21 16:49:45.000235:  20651  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/0219b7b4-c825-4abf-b53a-3262744521de/model.MODULE_e899a005793b73bcce61+2c2d707e.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/0219b7b4-c825-4abf-b53a-3262744521de/model.MODULE_e899a005793b73bcce61+2c2d707e.neff --model-type=transformer --auto-cast=none --verbose=35\n",
      "....performing partition vectorization on AG_2[[0, 25, 0, 0, 0]]{1 nodes (1 sources, 0 stops)}. dags covered: {dag_25_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 28, 0, 0, 0]]{3 nodes (1 sources, 0 stops)}. dags covered: {dag_28, dag_33_TRANSPOSE_DST, dag_34_TC_SRC}\n",
      "performing partition vectorization on AG_2[[0, 25, 0, 0, 0]]{1 nodes (1 sources, 0 stops)}. dags covered: {dag_25_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 28, 0, 0, 0]]{3 nodes (1 sources, 0 stops)}. dags covered: {dag_28, dag_33_TRANSPOSE_DST, dag_34_TC_SRC}\n",
      "performing partition vectorization on AG_2[[0, 12, 0, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_12_TC_DST, dag_13_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 21, 0, 0]]{3 nodes (1 sources, 0 stops)}. dags covered: {dag_21_TRANSPOSE_DST, dag_22_TRANSPOSE_DST, dag_23_TC_SRC}\n",
      "......performing partition vectorization on AG_2[[0, 9, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_10_TRANSPOSE_SRC, dag_9_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 14, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_14_TRANSPOSE_DST, dag_15_TC_SRC}\n",
      "performing partition vectorization on AG_2[[0, 16, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_16_TC_DST, dag_17_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 61, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_61_TC_DST, dag_62_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 66, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_66_TRANSPOSE_DST, dag_67_TC_SRC}\n",
      "performing partition vectorization on AG_2[[0, 68, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_68_TC_DST, dag_69_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 113, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_113_TC_DST, dag_114_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 118, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_119_TC_SRC, dag_118_TRANSPOSE_DST}\n",
      "performing partition vectorization on AG_2[[0, 120, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_121_TRANSPOSE_SRC, dag_120_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 165, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_165_TC_DST, dag_166_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 170, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_170_TRANSPOSE_DST, dag_171_TC_SRC}\n",
      "performing partition vectorization on AG_2[[0, 172, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_173_TRANSPOSE_SRC, dag_172_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 217, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_218_TRANSPOSE_SRC, dag_217_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 222, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_222_TRANSPOSE_DST, dag_223_TC_SRC}\n",
      "performing partition vectorization on AG_2[[0, 224, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_225_TRANSPOSE_SRC, dag_224_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 269, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_269_TC_DST, dag_270_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 274, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_274_TRANSPOSE_DST, dag_275_TC_SRC}\n",
      "performing partition vectorization on AG_2[[0, 276, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_276_TC_DST, dag_277_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 321, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_321_TC_DST, dag_322_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 326, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_327_TC_SRC, dag_326_TRANSPOSE_DST}\n",
      "performing partition vectorization on AG_2[[0, 328, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_328_TC_DST, dag_329_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 373, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_373_TC_DST, dag_374_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 378, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_378_TRANSPOSE_DST, dag_379_TC_SRC}\n",
      "performing partition vectorization on AG_2[[0, 380, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_380_TC_DST, dag_381_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 425, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_426_TRANSPOSE_SRC, dag_425_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 430, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_430_TRANSPOSE_DST, dag_431_TC_SRC}\n",
      "performing partition vectorization on AG_2[[0, 432, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_432_TC_DST, dag_433_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 477, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_478_TRANSPOSE_SRC, dag_477_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 482, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_483_TC_SRC, dag_482_TRANSPOSE_DST}\n",
      "performing partition vectorization on AG_2[[0, 484, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_485_TRANSPOSE_SRC, dag_484_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 529, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_529_TC_DST, dag_530_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 534, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_534_TRANSPOSE_DST, dag_535_TC_SRC}\n",
      "performing partition vectorization on AG_2[[0, 536, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_536_TC_DST, dag_537_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 581, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_582_TRANSPOSE_SRC, dag_581_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 586, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_586_TRANSPOSE_DST, dag_587_TC_SRC}\n",
      "performing partition vectorization on AG_2[[0, 588, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_588_TC_DST, dag_589_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 633, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_633_TC_DST, dag_634_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 638, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_638_TRANSPOSE_DST, dag_639_TC_SRC}\n",
      "performing partition vectorization on AG_2[[0, 640, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_640_TC_DST, dag_641_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 685, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_685_TC_DST, dag_686_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 690, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_691_TC_SRC, dag_690_TRANSPOSE_DST}\n",
      "performing partition vectorization on AG_2[[0, 692, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_693_TRANSPOSE_SRC, dag_692_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 737, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_737_TC_DST, dag_738_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 742, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_742_TRANSPOSE_DST, dag_743_TC_SRC}\n",
      "performing partition vectorization on AG_2[[0, 744, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_745_TRANSPOSE_SRC, dag_744_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 789, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_790_TRANSPOSE_SRC, dag_789_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 794, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_794_TRANSPOSE_DST, dag_795_TC_SRC}\n",
      "performing partition vectorization on AG_2[[0, 796, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_796_TC_DST, dag_797_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 841, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_841_TC_DST, dag_842_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 846, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_847_TC_SRC, dag_846_TRANSPOSE_DST}\n",
      "performing partition vectorization on AG_2[[0, 848, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_849_TRANSPOSE_SRC, dag_848_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 893, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_893_TC_DST, dag_894_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 898, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_898_TRANSPOSE_DST, dag_899_TC_SRC}\n",
      "performing partition vectorization on AG_2[[0, 900, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_901_TRANSPOSE_SRC, dag_900_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 945, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_946_TRANSPOSE_SRC, dag_945_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 950, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_950_TRANSPOSE_DST, dag_951_TC_SRC}\n",
      "performing partition vectorization on AG_2[[0, 952, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_952_TC_DST, dag_953_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 997, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_998_TRANSPOSE_SRC, dag_997_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 1002, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1002_TRANSPOSE_DST, dag_1003_TC_SRC}\n",
      "performing partition vectorization on AG_2[[0, 1004, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1004_TC_DST, dag_1005_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 1049, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1050_TRANSPOSE_SRC, dag_1049_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 1054, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1055_TC_SRC, dag_1054_TRANSPOSE_DST}\n",
      "performing partition vectorization on AG_2[[0, 1056, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1057_TRANSPOSE_SRC, dag_1056_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 1101, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1101_TC_DST, dag_1102_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 1106, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1106_TRANSPOSE_DST, dag_1107_TC_SRC}\n",
      "performing partition vectorization on AG_2[[0, 1108, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1108_TC_DST, dag_1109_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 1153, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1154_TRANSPOSE_SRC, dag_1153_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 1158, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1158_TRANSPOSE_DST, dag_1159_TC_SRC}\n",
      "performing partition vectorization on AG_2[[0, 1160, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1160_TC_DST, dag_1161_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 1205, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1206_TRANSPOSE_SRC, dag_1205_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 1210, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1210_TRANSPOSE_DST, dag_1211_TC_SRC}\n",
      "performing partition vectorization on AG_2[[0, 1212, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1213_TRANSPOSE_SRC, dag_1212_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 1257, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1258_TRANSPOSE_SRC, dag_1257_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 1262, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1262_TRANSPOSE_DST, dag_1263_TC_SRC}\n",
      "performing partition vectorization on AG_2[[0, 1264, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1265_TRANSPOSE_SRC, dag_1264_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 1309, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1310_TRANSPOSE_SRC, dag_1309_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 1314, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1314_TRANSPOSE_DST, dag_1315_TC_SRC}\n",
      "performing partition vectorization on AG_2[[0, 1316, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1317_TRANSPOSE_SRC, dag_1316_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 1361, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1361_TC_DST, dag_1362_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 1366, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1366_TRANSPOSE_DST, dag_1367_TC_SRC}\n",
      "performing partition vectorization on AG_2[[0, 1368, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1368_TC_DST, dag_1369_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 1413, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1413_TC_DST, dag_1414_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 1418, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1419_TC_SRC, dag_1418_TRANSPOSE_DST}\n",
      "performing partition vectorization on AG_2[[0, 1420, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1421_TRANSPOSE_SRC, dag_1420_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 1465, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1465_TC_DST, dag_1466_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 1470, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1470_TRANSPOSE_DST, dag_1471_TC_SRC}\n",
      "performing partition vectorization on AG_2[[0, 1472, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1473_TRANSPOSE_SRC, dag_1472_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 1517, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1518_TRANSPOSE_SRC, dag_1517_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 1522, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1522_TRANSPOSE_DST, dag_1523_TC_SRC}\n",
      "performing partition vectorization on AG_2[[0, 1524, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1525_TRANSPOSE_SRC, dag_1524_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 1569, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1570_TRANSPOSE_SRC, dag_1569_TC_DST}\n",
      "performing partition vectorization on AG_2[[0, 1574, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1574_TRANSPOSE_DST, dag_1575_TC_SRC}\n",
      "performing partition vectorization on AG_2[[0, 1576, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1576_TC_DST, dag_1577_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 1621, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1621_TC_DST, dag_1622_TRANSPOSE_SRC}\n",
      "performing partition vectorization on AG_2[[0, 1626, 0, 0]]{2 nodes (1 sources, 0 stops)}. dags covered: {dag_1627_TC_SRC, dag_1626_TRANSPOSE_DST}\n",
      "..................................................................................................................\n",
      "Compiler status PASS\n",
      "2024-05-21 17:10:25.000716:  20651  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "........................................................................................................................................................................................................................................................\n",
      "2024-05-21 18:33:15.000555:  20650  ERROR ||NEURON_CC_WRAPPER||: Failed compilation with ['neuronx-cc', 'compile', '--target=trn1', '--framework=XLA', '/tmp/ubuntu/neuroncc_compile_workdir/dd215b5d-e505-476c-9154-4ffa49973022/model.MODULE_0ee6a82628ec518e67cf+2c2d707e.hlo_module.pb', '--output', '/tmp/ubuntu/neuroncc_compile_workdir/dd215b5d-e505-476c-9154-4ffa49973022/model.MODULE_0ee6a82628ec518e67cf+2c2d707e.neff', '--model-type=transformer', '--auto-cast=none', '--verbose=35']: 2024-05-21T18:33:14Z [XCG815]  Estimated peak HBM usage (32.264610) exceeds 16GB. Neff won't be able to load on chip - Please open a support ticket at https://github.com/aws-neuron/aws-neuron-sdk/issues/new\n",
      "\n",
      "2024-05-21 18:33:15.000559:  20650  ERROR ||NEURON_CC_WRAPPER||: Compilation failed for /tmp/ubuntu/neuroncc_compile_workdir/dd215b5d-e505-476c-9154-4ffa49973022/model.MODULE_0ee6a82628ec518e67cf+2c2d707e.hlo_module.pb after 0 retries.\n",
      "2024-05-21 18:33:15.000564:  20650  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['neuronx-cc', 'compile', '--target=trn1', '--framework=XLA', '/tmp/ubuntu/neuroncc_compile_workdir/dd215b5d-e505-476c-9154-4ffa49973022/model.MODULE_0ee6a82628ec518e67cf+2c2d707e.hlo_module.pb', '--output', '/tmp/ubuntu/neuroncc_compile_workdir/dd215b5d-e505-476c-9154-4ffa49973022/model.MODULE_0ee6a82628ec518e67cf+2c2d707e.neff', '--model-type=transformer', '--auto-cast=none', '--verbose=35']' returned non-zero exit status 70.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 239, in _process_worker\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\n  File \"/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/transformers_neuronx/compiler.py\", line 462, in compile\n    self.build()\n  File \"/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/transformers_neuronx/compiler.py\", line 469, in build\n    self.neff_bytes = compile_hlo_module(self.hlo_module, self.tag)\n  File \"/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/transformers_neuronx/compiler.py\", line 121, in compile_hlo_module\n    neff_bytes = neuron_xla_compile(module_bytes, flags, input_format=\"hlo\", platform_target=\"trn1\",\n  File \"/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/libneuronxla/neuron_cc_wrapper.py\", line 268, in neuron_xla_compile\n    neuron_xla_compile_impl(\n  File \"/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/libneuronxla/neuron_cc_wrapper.py\", line 344, in neuron_xla_compile_impl\n    ret = compile_with_cache(output, compile_cache, cache_key, execution_mode,\n  File \"/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/libneuronxla/neuron_cc_wrapper.py\", line 250, in compile_with_cache\n    raise (e)\n  File \"/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/libneuronxla/neuron_cc_wrapper.py\", line 227, in compile_with_cache\n    ret = call_neuron_compiler(\n  File \"/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/libneuronxla/neuron_cc_wrapper.py\", line 163, in call_neuron_compiler\n    raise subprocess.CalledProcessError(res.returncode, cmd, stderr=error_info)\nsubprocess.CalledProcessError: Command '['neuronx-cc', 'compile', '--target=trn1', '--framework=XLA', '/tmp/ubuntu/neuroncc_compile_workdir/dd215b5d-e505-476c-9154-4ffa49973022/model.MODULE_0ee6a82628ec518e67cf+2c2d707e.hlo_module.pb', '--output', '/tmp/ubuntu/neuroncc_compile_workdir/dd215b5d-e505-476c-9154-4ffa49973022/model.MODULE_0ee6a82628ec518e67cf+2c2d707e.neff', '--model-type=transformer', '--auto-cast=none', '--verbose=35']' returned non-zero exit status 70.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m      8\u001b[0m compiler_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_cores\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m8\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_cast_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbf16\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m      9\u001b[0m input_shapes \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     10\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence_length\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m32768\u001b[39m, \u001b[38;5;66;03m# max length to generate\u001b[39;00m\n\u001b[1;32m     11\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4\u001b[39m \u001b[38;5;66;03m# batch size for the model\u001b[39;00m\n\u001b[1;32m     12\u001b[0m   }\n\u001b[0;32m---> 14\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mNeuronModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvanilla_model_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcompiler_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(vanilla_model_id)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Save locally or upload to the HuggingFace Hub\u001b[39;00m\n",
      "File \u001b[0;32m/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/optimum/modeling_base.py:401\u001b[0m, in \u001b[0;36mOptimizedModel.from_pretrained\u001b[0;34m(cls, model_id, export, force_download, use_auth_token, cache_dir, subfolder, config, local_files_only, trust_remote_code, revision, **kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m     trust_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    399\u001b[0m from_pretrained_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_from_transformers \u001b[38;5;28;01mif\u001b[39;00m export \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_from_pretrained\n\u001b[0;32m--> 401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_pretrained_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/optimum/neuron/utils/require_utils.py:50\u001b[0m, in \u001b[0;36m_create_requires_function.<locals>.require_func.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m availability_function():\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires the `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` package. You can install it by running: pip \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstall \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m     )\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/optimum/neuron/modeling_decoder.py:323\u001b[0m, in \u001b[0;36mNeuronDecoderModel._from_transformers\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;129m@requires_transformers_neuronx\u001b[39m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_transformers\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;66;03m# Deprecate it when optimum uses `_export` as from_pretrained_method in a stable release.\u001b[39;00m\n\u001b[0;32m--> 323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/optimum/neuron/utils/require_utils.py:50\u001b[0m, in \u001b[0;36m_create_requires_function.<locals>.require_func.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m availability_function():\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires the `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` package. You can install it by running: pip \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstall \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m     )\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/optimum/neuron/modeling_decoder.py:371\u001b[0m, in \u001b[0;36mNeuronDecoderModel._export\u001b[0;34m(cls, model_id, config, use_auth_token, revision, task, batch_size, sequence_length, num_cores, auto_cast_type, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/optimum/neuron/modeling.py:671\u001b[0m, in \u001b[0;36mNeuronModelForCausalLM.__init__\u001b[0;34m(self, config, checkpoint_dir, compiled_dir, generation_config)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    666\u001b[0m     config: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPretrainedConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    669\u001b[0m     generation_config: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerationConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    670\u001b[0m ):\n\u001b[0;32m--> 671\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompiled_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompiled_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mneuron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mneuron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence_length\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/optimum/neuron/utils/require_utils.py:50\u001b[0m, in \u001b[0;36m_create_requires_function.<locals>.require_func.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m availability_function():\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires the `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` package. You can install it by running: pip \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstall \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m     )\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/optimum/neuron/modeling_decoder.py:215\u001b[0m, in \u001b[0;36mNeuronDecoderModel.__init__\u001b[0;34m(self, config, checkpoint_dir, compiled_dir, generation_config)\u001b[0m\n\u001b[1;32m    212\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNEURON_RT_NUM_CORES\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(num_cores)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# Load the model on neuron cores (if found in cache or compiled directory, the NEFF files\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# will be reloaded instead of compiled)\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m \u001b[43mneuronx_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_neuron\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m neuron_rt_num_cores \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNEURON_RT_NUM_CORES\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/transformers_neuronx/base.py:72\u001b[0m, in \u001b[0;36mNeuronModelBase.to_neuron\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_compiled_artifacts(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_artifacts_directory)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup()\n",
      "File \u001b[0;32m/opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages/transformers_neuronx/base.py:54\u001b[0m, in \u001b[0;36mNeuronModelBase.compile\u001b[0;34m(self, parallel_degree)\u001b[0m\n\u001b[1;32m     52\u001b[0m     neff_bytes_futures[hash_hlo(kernel\u001b[38;5;241m.\u001b[39mhlo_module)] \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39msubmit(kernel\u001b[38;5;241m.\u001b[39mcompile)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m kernel \u001b[38;5;129;01min\u001b[39;00m kernels:\n\u001b[0;32m---> 54\u001b[0m     kernel\u001b[38;5;241m.\u001b[39mneff_bytes \u001b[38;5;241m=\u001b[39m \u001b[43mneff_bytes_futures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mhash_hlo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhlo_module\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py:444\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 444\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['neuronx-cc', 'compile', '--target=trn1', '--framework=XLA', '/tmp/ubuntu/neuroncc_compile_workdir/dd215b5d-e505-476c-9154-4ffa49973022/model.MODULE_0ee6a82628ec518e67cf+2c2d707e.hlo_module.pb', '--output', '/tmp/ubuntu/neuroncc_compile_workdir/dd215b5d-e505-476c-9154-4ffa49973022/model.MODULE_0ee6a82628ec518e67cf+2c2d707e.neff', '--model-type=transformer', '--auto-cast=none', '--verbose=35']' returned non-zero exit status 70."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from optimum.neuron import NeuronModelForCausalLM\n",
    "\n",
    "# model id you want to compile\n",
    "vanilla_model_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "\n",
    "# configs for compiling model\n",
    "compiler_args = {\"num_cores\": 8 , \"auto_cast_type\": \"bf16\"}\n",
    "input_shapes = {\n",
    "  \"sequence_length\": 32768, # max length to generate\n",
    "  \"batch_size\": 4 # batch size for the model\n",
    "  }\n",
    "\n",
    "llm = NeuronModelForCausalLM.from_pretrained(vanilla_model_id, export=True, **input_shapes, **compiler_args)\n",
    "tokenizer = AutoTokenizer.from_pretrained(vanilla_model_id)\n",
    "\n",
    "# Save locally or upload to the HuggingFace Hub\n",
    "save_directory = \"./mixtral_neuron\"\n",
    "llm.save_pretrained(save_directory)\n",
    "tokenizer.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mllm\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
