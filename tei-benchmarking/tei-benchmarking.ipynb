{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEI Bulk Embedding Load Test\n",
    "\n",
    "I think a good workflow:\n",
    "\n",
    "1. Use load tests with k6 to do grid search (it handles failures well)\n",
    "2. Then use my scripts to confirm we get similar performance when making async calls\n",
    "\n",
    "Also need to include a demo of how to keep track of the order / tie a specific response to a given input record... apparently asyncio respects the ordering of requests..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from tei_benchmark import generate_batches, embed\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal:\n",
    "\n",
    "- Embed N chunks of data in total\n",
    "- Vary the batch_size of each request, as well as the concurrency of requests\n",
    "- Analyze the total time to complete, RPS, and latency to see which bs / concurrency combination is best.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 10, Concurrency Level: 5, Total Time: 1.77 seconds, RPS: 11.31, Embed per sec: 565.45\n"
     ]
    }
   ],
   "source": [
    "batches = generate_batches(\"This is a test\", bs=10, total_chunks=1000)\n",
    "results = await embed(batches, concurrency_level=5, collect_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 32, Concurrency Level: 5, Total Time: 1.66 seconds, RPS: 4.23, Embed per sec: 603.97\n"
     ]
    }
   ],
   "source": [
    "batches = generate_batches(\"This is a test\", bs=32, total_chunks=1000)\n",
    "results = await embed(batches, concurrency_level=5, collect_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed with status code 413: {\"error\":\"batch size 64 > maximum allowed batch size 32\",\"error_type\":\"Validation\"}\n",
      "Request failed with status code 413: {\"error\":\"batch size 64 > maximum allowed batch size 32\",\"error_type\":\"Validation\"}\n",
      "Request failed with status code 413: {\"error\":\"batch size 64 > maximum allowed batch size 32\",\"error_type\":\"Validation\"}\n",
      "Request failed with status code 413: {\"error\":\"batch size 64 > maximum allowed batch size 32\",\"error_type\":\"Validation\"}\n",
      "Request failed with status code 413: {\"error\":\"batch size 64 > maximum allowed batch size 32\",\"error_type\":\"Validation\"}\n",
      "Request failed with status code 413: {\"error\":\"batch size 64 > maximum allowed batch size 32\",\"error_type\":\"Validation\"}\n",
      "Request failed with status code 413: {\"error\":\"batch size 64 > maximum allowed batch size 32\",\"error_type\":\"Validation\"}\n",
      "Request failed with status code 413: {\"error\":\"batch size 64 > maximum allowed batch size 32\",\"error_type\":\"Validation\"}\n",
      "Request failed with status code 413: {\"error\":\"batch size 64 > maximum allowed batch size 32\",\"error_type\":\"Validation\"}\n",
      "Request failed with status code 413: {\"error\":\"batch size 64 > maximum allowed batch size 32\",\"error_type\":\"Validation\"}\n",
      "Request failed with status code 413: {\"error\":\"batch size 64 > maximum allowed batch size 32\",\"error_type\":\"Validation\"}\n",
      "Request failed with status code 413: {\"error\":\"batch size 64 > maximum allowed batch size 32\",\"error_type\":\"Validation\"}\n",
      "Request failed with status code 413: {\"error\":\"batch size 64 > maximum allowed batch size 32\",\"error_type\":\"Validation\"}\n",
      "Request failed with status code 413: {\"error\":\"batch size 64 > maximum allowed batch size 32\",\"error_type\":\"Validation\"}\n",
      "Request failed with status code 413: {\"error\":\"batch size 64 > maximum allowed batch size 32\",\"error_type\":\"Validation\"}\n",
      "Request failed with status code 413: {\"error\":\"batch size 40 > maximum allowed batch size 32\",\"error_type\":\"Validation\"}\n",
      "Batch Size: 64, Concurrency Level: 5, Total Time: 0.32 seconds, RPS: 12.31, Embed per sec: 3077.87\n"
     ]
    }
   ],
   "source": [
    "batches = generate_batches(\"This is a test\", bs=64, total_chunks=1000)\n",
    "results = await embed(batches, concurrency_level=5, collect_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_experiments():\n",
    "    batch_sizes = [1, 4, 8, 16, 32]\n",
    "    concurrency_levels = [1, 25, 50, 100, 205, 500, 1000]\n",
    "\n",
    "    results = []\n",
    "    for batch_size in batch_sizes[-2:]:\n",
    "        for concurrency_level in concurrency_levels[-2:]:\n",
    "            batches = generate_batches(\n",
    "                \"This is a test\", bs=batch_size, total_chunks=10_000\n",
    "            )\n",
    "            results.append(\n",
    "                await embed(\n",
    "                    batches,\n",
    "                    concurrency_level=concurrency_level,\n",
    "                    collect_embeddings=False,\n",
    "                )\n",
    "            )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 16, Concurrency Level: 500, Total Time: 5.50 seconds, RPS: 0.36, Embed per sec: 1816.56\n",
      "Batch Size: 16, Concurrency Level: 1000, Total Time: 5.19 seconds, RPS: 0.19, Embed per sec: 1927.15\n",
      "Batch Size: 32, Concurrency Level: 500, Total Time: 5.33 seconds, RPS: 0.19, Embed per sec: 1877.69\n",
      "Batch Size: 32, Concurrency Level: 1000, Total Time: 5.31 seconds, RPS: 0.19, Embed per sec: 1884.80\n"
     ]
    }
   ],
   "source": [
    "results = await run_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 16,\n",
       " 'concurrency_level': 500,\n",
       " 'total_time': 5.5049,\n",
       " 'num_chunks_embedded': 10000,\n",
       " 'req_per_sec': 0.3633,\n",
       " 'embed_per_sec': 1816.5634}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0][\"metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K6 Load Test Grid Search\n",
    "\n",
    "To-do\n",
    "\n",
    "1. k6 script that runs load test at set RPS. Inputs are batch size and rate. We capture the actual achieved RPS and a boolean indication of if any requests are dropped.\n",
    "2. Write a python script that iterates through a grid search of RPS and batch sizes.\n",
    "3. Monitor which combination can embed the highest effective number chunks per second.\n",
    "4. Visualize this? (Maybe plot latency vs. throughput like TGI does?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"test_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Inference Client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(model=os.getenv(\"HOST\"), token=os.getenv(\"HF_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = client.feature_extraction(\"This is a test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241m.\u001b[39mcontent\n",
      "\u001b[0;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
