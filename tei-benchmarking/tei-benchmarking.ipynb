{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEI Bulk Embedding Load Test\n",
    "\n",
    "I think a good workflow:\n",
    "\n",
    "1. Use load tests with k6 to do grid search (it handles failures well)\n",
    "2. Then use my scripts to confirm we get similar performance when making async calls\n",
    "\n",
    "Also need to include a demo of how to keep track of the order / tie a specific response to a given input record... apparently asyncio respects the ordering of requests..\n",
    "\n",
    "Resources:\n",
    "\n",
    "- On asyncio in Python: https://superfastpython.com/asyncio-gather/\n",
    "- On `as_completed()` vs. `gather()`: https://jxnl.github.io/instructor/blog/2023/11/13/learn-async/#asyncioas_completed-handling-tasks-as-they-complete\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal:\n",
    "\n",
    "- Embed N chunks of data in total\n",
    "- Vary the batch_size of each request, as well as the concurrency of requests\n",
    "- Analyze the total time to complete, RPS, and latency to see which bs / concurrency combination is best.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 10, Concurrency Level: 5, Total Time: 1.77 seconds, RPS: 11.31, Embed per sec: 565.45\n"
     ]
    }
   ],
   "source": [
    "batches = generate_batches(\"This is a test\", bs=10, total_chunks=1000)\n",
    "results = await embed(batches, concurrency_level=5, collect_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from tei_bulk_embed_test import main\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\"unique_id\": n, \"text\": f\"This is a test sentence - {n}\"} for n in range(50_000)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timing Metrics Statistics: \n",
      "\n",
      "\n",
      "total_time:\n",
      "  mean: 1.321 seconds\n",
      "  min: 0.298 seconds\n",
      "  median: 1.404 seconds\n",
      "  max: 2.007 seconds\n",
      "  p90: 1.596 seconds\n",
      "  p95: 1.652 seconds\n",
      "\n",
      "tokenization_time:\n",
      "  mean: 0.0201 seconds\n",
      "  min: 0.0 seconds\n",
      "  median: 0.018 seconds\n",
      "  max: 0.071 seconds\n",
      "  p90: 0.039 seconds\n",
      "  p95: 0.043 seconds\n",
      "\n",
      "queue_time:\n",
      "  mean: 0.5067 seconds\n",
      "  min: 0.004 seconds\n",
      "  median: 0.403 seconds\n",
      "  max: 0.947 seconds\n",
      "  p90: 0.743 seconds\n",
      "  p95: 0.896 seconds\n",
      "\n",
      "inference_time:\n",
      "  mean: 0.444 seconds\n",
      "  min: 0.02 seconds\n",
      "  median: 0.564 seconds\n",
      "  max: 0.681 seconds\n",
      "  p90: 0.574 seconds\n",
      "  p95: 0.575 seconds\n",
      "\n",
      "\n",
      "Total pipeline execution time (time to embed all data): 25.2797 seconds\n",
      "Total number of chunks to embed: 50000\n",
      "Total number of chunks embedded: 50000\n",
      "Total number of chunks that hit an error: 0\n",
      "Embeddings per second (completed requests): 1977.8715728430323\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "concurrency = 1000\n",
    "\n",
    "# os.remove(\"embeddings.jsonl\")\n",
    "results = await main(data, batch_size, concurrency, filename=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'timing_statistics': {'total_time': {'mean': 1344.69184,\n",
       "   'min': 54.0,\n",
       "   'median': 1343.0,\n",
       "   'max': 1818.0,\n",
       "   'p90': 1637.0,\n",
       "   'p95': 1711.0},\n",
       "  'tokenization_time': {'mean': 17.05504,\n",
       "   'min': 0.0,\n",
       "   'median': 16.0,\n",
       "   'max': 70.0,\n",
       "   'p90': 32.0,\n",
       "   'p95': 38.0},\n",
       "  'queue_time': {'mean': 550.98144,\n",
       "   'min': 4.0,\n",
       "   'median': 514.0,\n",
       "   'max': 907.0,\n",
       "   'p90': 721.0,\n",
       "   'p95': 893.0},\n",
       "  'inference_time': {'mean': 404.72544,\n",
       "   'min': 27.0,\n",
       "   'median': 452.0,\n",
       "   'max': 459.0,\n",
       "   'p90': 456.0,\n",
       "   'p95': 458.0}},\n",
       " 'total_time': 25.407,\n",
       " 'embeddings_per_second': 1967.961585389853,\n",
       " 'success_metrics': {'success': 50000, 'failure': 0, 'total': 50000}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_experiments():\n",
    "    batch_sizes = [1, 4, 8, 16, 32]\n",
    "    concurrency_levels = [1, 25, 50, 100, 205, 500, 1000]\n",
    "\n",
    "    results = []\n",
    "    for batch_size in batch_sizes[-2:]:\n",
    "        for concurrency_level in concurrency_levels[-2:]:\n",
    "            batches = generate_batches(\n",
    "                \"This is a test\", bs=batch_size, total_chunks=10_000\n",
    "            )\n",
    "            results.append(\n",
    "                await embed(\n",
    "                    batches,\n",
    "                    concurrency_level=concurrency_level,\n",
    "                    collect_embeddings=False,\n",
    "                )\n",
    "            )\n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
